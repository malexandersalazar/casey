{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsAPIClient:\n",
    "    \"\"\"Base class for news API clients\"\"\"\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.session = requests.Session()\n",
    "\n",
    "class BingNewsAPI(NewsAPIClient):\n",
    "    \"\"\"Client for Bing News Search API\"\"\"\n",
    "    def __init__(self, api_key: str):\n",
    "        super().__init__(api_key)\n",
    "        self.base_url = \"https://api.bing.microsoft.com/v7.0/news/search\"\n",
    "        self.session.headers.update({\n",
    "            'Ocp-Apim-Subscription-Key': self.api_key\n",
    "        })\n",
    "\n",
    "    def search_news(self, query: str, count: int = 10) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Search news articles using Bing News API\n",
    "        \n",
    "        Args:\n",
    "            query: Search term\n",
    "            count: Number of results to return (max 100)\n",
    "            \n",
    "        Returns:\n",
    "            List of news articles\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            'q': query,\n",
    "            'count': min(count, 100),\n",
    "            'freshness': 'Day'\n",
    "        }\n",
    "        \n",
    "        response = self.session.get(self.base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        results = response.json()\n",
    "        return results.get('value', [])\n",
    "\n",
    "class RedditAPI(NewsAPIClient):\n",
    "    \"\"\"Client for Reddit API\"\"\"\n",
    "    def __init__(self, client_id: str, client_secret: str):\n",
    "        self.client_id = client_id\n",
    "        self.client_secret = client_secret\n",
    "        self.base_url = \"https://oauth.reddit.com\"\n",
    "        self.session = requests.Session()\n",
    "        self._get_access_token()\n",
    "\n",
    "    def _get_access_token(self):\n",
    "        \"\"\"Authenticate with Reddit and get access token\"\"\"\n",
    "        auth = requests.auth.HTTPBasicAuth(self.client_id, self.client_secret)\n",
    "        data = {\n",
    "            'grant_type': 'client_credentials'\n",
    "        }\n",
    "        headers = {\n",
    "            'User-Agent': 'NewsAggregator/1.0'\n",
    "        }\n",
    "        \n",
    "        response = requests.post(\n",
    "            'https://www.reddit.com/api/v1/access_token',\n",
    "            auth=auth,\n",
    "            data=data,\n",
    "            headers=headers\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        self.session.headers.update({\n",
    "            'Authorization': f\"Bearer {response.json()['access_token']}\",\n",
    "            'User-Agent': 'NewsAggregator/1.0'\n",
    "        })\n",
    "\n",
    "    def get_subreddit_top(self, subreddit: str, limit: int = 10) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Get top posts from a subreddit\n",
    "        \n",
    "        Args:\n",
    "            subreddit: Subreddit name without 'r/'\n",
    "            limit: Number of posts to return\n",
    "            \n",
    "        Returns:\n",
    "            List of posts\n",
    "        \"\"\"\n",
    "        url = f\"{self.base_url}/r/{subreddit}/top\"\n",
    "        params = {\n",
    "            'limit': limit,\n",
    "            't': 'day'  # Time filter: hour, day, week, month, year, all\n",
    "        }\n",
    "        \n",
    "        response = self.session.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        posts = response.json()['data']['children']\n",
    "        return [post['data'] for post in posts]\n",
    "\n",
    "class NewsAggregator:\n",
    "    \"\"\"Aggregate news from multiple sources\"\"\"\n",
    "    def __init__(self, \n",
    "                 bing_api_key: Optional[str] = None,\n",
    "                 reddit_client_id: Optional[str] = None,\n",
    "                 reddit_client_secret: Optional[str] = None):\n",
    "        self.clients = {}\n",
    "        \n",
    "        if bing_api_key:\n",
    "            self.clients['bing'] = BingNewsAPI(bing_api_key)\n",
    "        if reddit_client_id and reddit_client_secret:\n",
    "            self.clients['reddit'] = RedditAPI(reddit_client_id, reddit_client_secret)\n",
    "\n",
    "    def get_news(self, query: str, sources: List[str] = None) -> Dict[str, List[Dict]]:\n",
    "        \"\"\"\n",
    "        Get news from all configured sources\n",
    "        \n",
    "        Args:\n",
    "            query: Search term\n",
    "            sources: List of sources to query (defaults to all configured sources)\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary mapping source names to lists of articles\n",
    "        \"\"\"\n",
    "        if sources is None:\n",
    "            sources = self.clients.keys()\n",
    "            \n",
    "        results = {}\n",
    "        \n",
    "        for source in sources:\n",
    "            if source not in self.clients:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                if source == 'bing':\n",
    "                    results[source] = self.clients[source].search_news(query)\n",
    "                elif source == 'reddit':\n",
    "                    # For Reddit, use the query as a subreddit name\n",
    "                    results[source] = self.clients[source].get_subreddit_top(query)\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching from {source}: {str(e)}\")\n",
    "                results[source] = []\n",
    "                \n",
    "        return results\n",
    "\n",
    "def main():\n",
    "    # Load API keys from environment variables\n",
    "    bing_api_key = os.getenv('BING_API_KEY')\n",
    "    reddit_client_id = os.getenv('REDDIT_CLIENT_ID')\n",
    "    reddit_client_secret = os.getenv('REDDIT_CLIENT_SECRET')\n",
    "    \n",
    "    # Initialize aggregator\n",
    "    aggregator = NewsAggregator(\n",
    "        bing_api_key=bing_api_key,\n",
    "        reddit_client_id=reddit_client_id,\n",
    "        reddit_client_secret=reddit_client_secret\n",
    "    )\n",
    "    \n",
    "    # Example usage\n",
    "    results = aggregator.get_news(\n",
    "        query=\"artificial intelligence\",\n",
    "        sources=['bing', 'reddit']\n",
    "    )\n",
    "    \n",
    "    # Print results\n",
    "    for source, articles in results.items():\n",
    "        print(f\"\\n=== {source.upper()} NEWS ===\")\n",
    "        for article in articles[:3]:  # Print first 3 articles\n",
    "            if source == 'bing':\n",
    "                print(f\"Title: {article.get('name')}\")\n",
    "                print(f\"Description: {article.get('description')}\")\n",
    "                print(f\"URL: {article.get('url')}\\n\")\n",
    "            elif source == 'reddit':\n",
    "                print(f\"Title: {article.get('title')}\")\n",
    "                print(f\"Score: {article.get('score')}\")\n",
    "                print(f\"URL: https://reddit.com{article.get('permalink')}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Active Subreddits:\n",
      "BrandNewSentence: 1 posts\n",
      "memes: 1 posts\n",
      "meirl: 1 posts\n",
      "shittymoviedetails: 1 posts\n",
      "WorkReform: 1 posts\n",
      "nextfuckinglevel: 1 posts\n",
      "mildlyinfuriating: 1 posts\n",
      "Futurology: 1 posts\n",
      "clevercomebacks: 1 posts\n",
      "MurderedByWords: 1 posts\n",
      "\n",
      "Top 10 Trending Posts:\n",
      "\n",
      "Title: Imagine…\n",
      "Subreddit: r/BrandNewSentence\n",
      "Score: 55,555\n",
      "Comments: 741\n",
      "URL: https://reddit.com/r/BrandNewSentence/comments/1h88k64/imagine/\n",
      "\n",
      "Title: It gets dumber \n",
      "Subreddit: r/memes\n",
      "Score: 42,457\n",
      "Comments: 666\n",
      "URL: https://reddit.com/r/memes/comments/1h86ihq/it_gets_dumber/\n",
      "\n",
      "Title: meirl\n",
      "Subreddit: r/meirl\n",
      "Score: 42,452\n",
      "Comments: 88\n",
      "URL: https://reddit.com/r/meirl/comments/1h884xw/meirl/\n",
      "\n",
      "Title: The Austin Powers series is a parody of early James Bond movies, this is emphasised by the fact Austin respects a women’s consent \n",
      "Subreddit: r/shittymoviedetails\n",
      "Score: 34,634\n",
      "Comments: 541\n",
      "URL: https://reddit.com/r/shittymoviedetails/comments/1h8a25g/the_austin_powers_series_is_a_parody_of_early/\n",
      "\n",
      "Title: Rep. Dean Phillips is the only politician I've seen so far actually acknowledge our rage toward UnitedHealth\n",
      "Subreddit: r/WorkReform\n",
      "Score: 31,188\n",
      "Comments: 938\n",
      "URL: https://reddit.com/r/WorkReform/comments/1h86zkw/rep_dean_phillips_is_the_only_politician_ive_seen/\n",
      "\n",
      "Title: Lifestyle-based Fitness v. Livelihood-based Fitness\n",
      "Subreddit: r/nextfuckinglevel\n",
      "Score: 30,380\n",
      "Comments: 1,155\n",
      "URL: https://reddit.com/r/nextfuckinglevel/comments/1h8c011/lifestylebased_fitness_v_livelihoodbased_fitness/\n",
      "\n",
      "Title: This absolute buffoon blocked me in my garage less than an hour before I needed to take a final exam\n",
      "Subreddit: r/mildlyinfuriating\n",
      "Score: 29,374\n",
      "Comments: 742\n",
      "URL: https://reddit.com/r/mildlyinfuriating/comments/1h8cx3k/this_absolute_buffoon_blocked_me_in_my_garage/\n",
      "\n",
      "Title: Murdered Insurance CEO Had Deployed an AI to Automatically Deny Benefits for Sick People\n",
      "Subreddit: r/Futurology\n",
      "Score: 25,308\n",
      "Comments: 1,214\n",
      "URL: https://reddit.com/r/Futurology/comments/1h8h483/murdered_insurance_ceo_had_deployed_an_ai_to/\n",
      "\n",
      "Title: This was supposed to happen \n",
      "Subreddit: r/clevercomebacks\n",
      "Score: 25,265\n",
      "Comments: 664\n",
      "URL: https://reddit.com/r/clevercomebacks/comments/1h89wgg/this_was_supposed_to_happen/\n",
      "\n",
      "Title: Yes they should be at border \n",
      "Subreddit: r/MurderedByWords\n",
      "Score: 19,888\n",
      "Comments: 84\n",
      "URL: https://reddit.com/r/MurderedByWords/comments/1h89xn5/yes_they_should_be_at_border/\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def get_trending_topics():\n",
    "    # Initialize Reddit instance\n",
    "    # You'll need to replace these with your own credentials from https://www.reddit.com/prefs/apps\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=os.getenv('REDDIT_CLIENT_ID'),\n",
    "        client_secret=os.getenv('REDDIT_CLIENT_SECRET'),\n",
    "        user_agent=\"trending_topics_script_v1.0\"\n",
    "    )\n",
    "    \n",
    "    # Get trending posts from r/all\n",
    "    trending_posts = []\n",
    "    \n",
    "    # Get top posts from the past 24 hours\n",
    "    for submission in reddit.subreddit('all').hot(limit=50):\n",
    "        post_data = {\n",
    "            'title': submission.title,\n",
    "            'subreddit': submission.subreddit.display_name,\n",
    "            'score': submission.score,\n",
    "            'comments': submission.num_comments,\n",
    "            'url': f'https://reddit.com{submission.permalink}',\n",
    "            'created_utc': datetime.fromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'upvote_ratio': submission.upvote_ratio\n",
    "        }\n",
    "        trending_posts.append(post_data)\n",
    "    \n",
    "    # Convert to DataFrame for easier analysis\n",
    "    df = pd.DataFrame(trending_posts)\n",
    "    \n",
    "    # Sort by score to get the most popular posts\n",
    "    df = df.sort_values('score', ascending=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def analyze_trends(df):\n",
    "    # Get most active subreddits\n",
    "    subreddit_counts = df['subreddit'].value_counts().head(10)\n",
    "    \n",
    "    print(\"\\nMost Active Subreddits:\")\n",
    "    for subreddit, count in subreddit_counts.items():\n",
    "        print(f\"{subreddit}: {count} posts\")\n",
    "    \n",
    "    print(\"\\nTop 10 Trending Posts:\")\n",
    "    for _, post in df.head(10).iterrows():\n",
    "        print(f\"\\nTitle: {post['title']}\")\n",
    "        print(f\"Subreddit: r/{post['subreddit']}\")\n",
    "        print(f\"Score: {post['score']:,}\")\n",
    "        print(f\"Comments: {post['comments']:,}\")\n",
    "        print(f\"URL: {post['url']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get trending topics\n",
    "    trending_df = get_trending_topics()\n",
    "    \n",
    "    # Analyze and display trends\n",
    "    analyze_trends(trending_df)\n",
    "    \n",
    "    # Optionally save to CSV\n",
    "    trending_df.to_csv('trending_topics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_news_api = BingNewsAPI(os.getenv('BING_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bing_data \u001b[38;5;241m=\u001b[39m \u001b[43mbing_news_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_news\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAI trends\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m bing_data_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(bing_data)\n",
      "Cell \u001b[1;32mIn[33], line 33\u001b[0m, in \u001b[0;36mBingNewsAPI.search_news\u001b[1;34m(self, query, count)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03mSearch news articles using Bing News API\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    List of news articles\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m: query,\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mmin\u001b[39m(count, \u001b[38;5;241m100\u001b[39m),\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreshness\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDay\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     31\u001b[0m }\n\u001b[1;32m---> 33\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     36\u001b[0m results \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32md:\\malexandersalazar\\casey\\src\\.venv\\lib\\site-packages\\requests\\sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \n\u001b[0;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\malexandersalazar\\casey\\src\\.venv\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32md:\\malexandersalazar\\casey\\src\\.venv\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32md:\\malexandersalazar\\casey\\src\\.venv\\lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32md:\\malexandersalazar\\casey\\src\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\malexandersalazar\\casey\\src\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32md:\\malexandersalazar\\casey\\src\\.venv\\lib\\site-packages\\urllib3\\connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32m~\\.conda\\envs\\py31\\lib\\http\\client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\.conda\\envs\\py31\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\py31\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\py31\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\py31\\lib\\ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\.conda\\envs\\py31\\lib\\ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bing_data = bing_news_api.search_news('AI trends')\n",
    "bing_data_df = pd.DataFrame(bing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_data_df.iloc[0].url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import time\n",
    "import logging\n",
    "import asyncio\n",
    "import platform\n",
    "import nest_asyncio\n",
    "from typing import List, Dict, Set\n",
    "\n",
    "import certifi\n",
    "import aiohttp\n",
    "from bs4 import BeautifulSoup\n",
    "from aiohttp import ClientTimeout\n",
    "from fake_useragent import UserAgent\n",
    "from aiohttp_retry import RetryClient, ExponentialRetry\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "class FastNewsScraper:\n",
    "    \"\"\"Asynchronous news content scraper optimized for speed\"\"\"\n",
    "    \n",
    "    def __init__(self, max_concurrent: int = 50, timeout: int = 10):\n",
    "        self.max_concurrent = max_concurrent\n",
    "        self.timeout = ClientTimeout(total=timeout)\n",
    "        self.ua = UserAgent()\n",
    "        self.seen_urls: Set[str] = set()\n",
    "        \n",
    "        # Configure logging\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Setup SSL context\n",
    "        self.ssl_context = ssl.create_default_context(cafile=certifi.where())\n",
    "\n",
    "    def _get_random_headers(self) -> Dict[str, str]:\n",
    "        \"\"\"Generate random headers for each request\"\"\"\n",
    "        return {\n",
    "            'User-Agent': self.ua.random,\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "\n",
    "    async def _extract_content(self, html: str) -> Dict[str, str]:\n",
    "        \"\"\"Extract content from HTML using BeautifulSoup with minimal parsing\"\"\"\n",
    "        try:\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            \n",
    "            # Quick removal of unnecessary elements\n",
    "            for tag in soup(['script', 'style', 'nav', 'footer', 'iframe', 'aside']):\n",
    "                tag.decompose()\n",
    "            \n",
    "            # Fast content extraction using common patterns\n",
    "            content = {\n",
    "                'title': '',\n",
    "                'text': '',\n",
    "                'metadata': {}\n",
    "            }\n",
    "            \n",
    "            # Quick title extraction\n",
    "            title_tag = (\n",
    "                soup.find('h1') or \n",
    "                soup.find('meta', property='og:title') or\n",
    "                soup.find('title')\n",
    "            )\n",
    "            if title_tag:\n",
    "                content['title'] = title_tag.get_text() if hasattr(title_tag, 'get_text') else title_tag.get('content', '')\n",
    "            \n",
    "            # Quick main content extraction\n",
    "            article_tag = (\n",
    "                soup.find('article') or\n",
    "                soup.find('div', class_=['article-content', 'story-content', 'post-content']) or\n",
    "                soup.find('div', {'itemprop': 'articleBody'})\n",
    "            )\n",
    "            \n",
    "            if article_tag:\n",
    "                # Extract text efficiently\n",
    "                paragraphs = article_tag.find_all('p')\n",
    "                content['text'] = '\\n'.join(p.get_text(strip=True) for p in paragraphs)\n",
    "            \n",
    "            return content\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Content extraction error: {str(e)}\")\n",
    "            return {'title': '', 'text': '', 'metadata': {}}\n",
    "\n",
    "    async def _fetch_url(self, session: aiohttp.ClientSession, url: str) -> Dict[str, str]:\n",
    "        \"\"\"Fetch and process a single URL\"\"\"\n",
    "        try:\n",
    "            retry_options = ExponentialRetry(attempts=2)\n",
    "            retry_client = RetryClient(client_session=session, retry_options=retry_options)\n",
    "            \n",
    "            async with retry_client.get(\n",
    "                url,\n",
    "                headers=self._get_random_headers(),\n",
    "                timeout=self.timeout,\n",
    "                ssl=self.ssl_context\n",
    "            ) as response:\n",
    "                if response.status == 200:\n",
    "                    html = await response.text()\n",
    "                    content = await self._extract_content(html)\n",
    "                    content['url'] = url\n",
    "                    content['status'] = 'success'\n",
    "                    return content\n",
    "                else:\n",
    "                    return {'url': url, 'status': 'error', 'error': f'HTTP {response.status}'}\n",
    "                    \n",
    "        except asyncio.TimeoutError:\n",
    "            return {'url': url, 'status': 'error', 'error': 'timeout'}\n",
    "        except Exception as e:\n",
    "            return {'url': url, 'status': 'error', 'error': str(e)}\n",
    "\n",
    "    async def scrape_urls(self, urls: List[str]) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Scrape multiple URLs concurrently\n",
    "        \n",
    "        Args:\n",
    "            urls: List of URLs to scrape\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing scraped content\n",
    "        \"\"\"\n",
    "        # Remove duplicates and already seen URLs\n",
    "        unique_urls = list(set(urls) - self.seen_urls)\n",
    "        self.seen_urls.update(unique_urls)\n",
    "        \n",
    "        if not unique_urls:\n",
    "            return []\n",
    "        \n",
    "        # Create connection pool\n",
    "        conn = aiohttp.TCPConnector(\n",
    "            limit=self.max_concurrent,\n",
    "            ttl_dns_cache=300,\n",
    "            ssl=self.ssl_context\n",
    "        )\n",
    "        \n",
    "        async with aiohttp.ClientSession(connector=conn) as session:\n",
    "            tasks = [\n",
    "                self._fetch_url(session, url)\n",
    "                for url in unique_urls\n",
    "            ]\n",
    "            \n",
    "            # Use semaphore to limit concurrent requests\n",
    "            semaphore = asyncio.Semaphore(self.max_concurrent)\n",
    "            async def bounded_fetch(task):\n",
    "                async with semaphore:\n",
    "                    return await task\n",
    "            \n",
    "            # Gather results with timeout\n",
    "            results = await asyncio.gather(\n",
    "                *(bounded_fetch(task) for task in tasks),\n",
    "                return_exceptions=True\n",
    "            )\n",
    "            \n",
    "            # Filter out failures and exceptions\n",
    "            valid_results = [\n",
    "                result for result in results\n",
    "                if isinstance(result, dict) and result.get('status') == 'success'\n",
    "            ]\n",
    "            \n",
    "            return valid_results\n",
    "\n",
    "def scrape_batch(urls: List[str], max_concurrent: int = 50, timeout: int = 10) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Synchronous wrapper for async scraping\n",
    "    \n",
    "    Args:\n",
    "        urls: List of URLs to scrape\n",
    "        max_concurrent: Maximum number of concurrent requests\n",
    "        timeout: Timeout in seconds for each request\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing scraped content\n",
    "    \"\"\"\n",
    "    scraper = FastNewsScraper(max_concurrent=max_concurrent, timeout=timeout)\n",
    "    \n",
    "    # Create new event loop\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "    except RuntimeError:\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "    \n",
    "    try:\n",
    "        results = loop.run_until_complete(scraper.scrape_urls(urls))\n",
    "    finally:\n",
    "        # Clean up\n",
    "        if platform.system() != 'Windows':  # Windows has issues with loop cleanup\n",
    "            loop.close()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_data_df.url.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: name 'time' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     urls \u001b[38;5;241m=\u001b[39m bing_data_df\u001b[38;5;241m.\u001b[39murl\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m----> 4\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      5\u001b[0m     results \u001b[38;5;241m=\u001b[39m scrape_batch(urls)\n\u001b[0;32m      6\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    urls = bing_data_df.url.tolist()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results = scrape_batch(urls)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Scraped {len(results)} articles in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    # Print first article preview\n",
    "    if results:\n",
    "        article = results[0]\n",
    "        print(f\"\\nExample article:\")\n",
    "        print(f\"Title: {article['title'][:100]}\")\n",
    "        print(f\"Content preview: {article['text'][:200]}...\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bing_data_df.iloc[0].url)\n",
    "print(bing_data_df.iloc[1].url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[0]['url'])\n",
    "print(results[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "class RedditNewsSearch:\n",
    "    def __init__(self):\n",
    "        # Initialize Reddit instance\n",
    "        self.reddit = praw.Reddit(\n",
    "            client_id=os.getenv('REDDIT_CLIENT_ID'),\n",
    "            client_secret=os.getenv('REDDIT_CLIENT_SECRET'),\n",
    "            user_agent=\"news_search_script_v1.0\"\n",
    "        )\n",
    "    \n",
    "    def search_reddit(self, query, limit=25, sort='relevance', time_filter='month'):\n",
    "        \"\"\"\n",
    "        Search across all of Reddit for specific topics\n",
    "        \n",
    "        Parameters:\n",
    "        - query: Search term\n",
    "        - limit: Number of results to return\n",
    "        - sort: One of 'relevance', 'hot', 'top', 'new', 'comments'\n",
    "        - time_filter: One of 'all', 'day', 'hour', 'month', 'week', 'year'\n",
    "        \"\"\"\n",
    "        search_results = []\n",
    "        \n",
    "        # Search across all subreddits\n",
    "        for submission in self.reddit.subreddit('all').search(\n",
    "            query,\n",
    "            sort=sort,\n",
    "            time_filter=time_filter,\n",
    "            limit=limit\n",
    "        ):\n",
    "            post_data = {\n",
    "                'title': submission.title,\n",
    "                'subreddit': submission.subreddit.display_name,\n",
    "                'score': submission.score,\n",
    "                'comments': submission.num_comments,\n",
    "                'url': submission.url,\n",
    "                'reddit_url': f'https://reddit.com{submission.permalink}',\n",
    "                'created_utc': datetime.fromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'upvote_ratio': submission.upvote_ratio,\n",
    "                'is_self': submission.is_self  # True if it's a text post\n",
    "            }\n",
    "            \n",
    "            # Get the post text if it's a self post\n",
    "            if submission.is_self:\n",
    "                post_data['text'] = submission.selftext\n",
    "            \n",
    "            search_results.append(post_data)\n",
    "        \n",
    "        return pd.DataFrame(search_results)\n",
    "\n",
    "    def filter_news_sources(self, df):\n",
    "        \"\"\"Filter results to focus on news-related content\"\"\"\n",
    "        news_subreddits = [\n",
    "            'news', 'worldnews', 'politics', 'technology',\n",
    "            'science', 'environment', 'business', 'economics',\n",
    "            'finance', 'health', 'education'\n",
    "        ]\n",
    "        \n",
    "        # Filter for news subreddits or posts containing news URLs\n",
    "        news_domains = ['reuters.com', 'apnews.com', 'bbc.com', 'nytimes.com', \n",
    "                       'theguardian.com', 'bloomberg.com', 'wsj.com']\n",
    "        \n",
    "        return df[\n",
    "            (df['subreddit'].isin(news_subreddits)) |\n",
    "            (df['url'].str.contains('|'.join(news_domains), case=False, na=False))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = RedditNewsSearch()\n",
    "\n",
    "# Get user input\n",
    "query = 'How AI will change of way to live'\n",
    "include_only_news = False\n",
    "\n",
    "# Perform search\n",
    "results = searcher.search_reddit(\n",
    "    query=query,\n",
    "    limit=50,\n",
    "    sort='relevance',\n",
    "    time_filter='month'\n",
    ")\n",
    "\n",
    "if include_only_news:\n",
    "    results = searcher.filter_news_sources(results)\n",
    "\n",
    "# Display results\n",
    "if len(results) == 0:\n",
    "    print(\"No results found.\")\n",
    "    \n",
    "print(f\"\\nFound {len(results)} results:\")\n",
    "for _, post in results.iterrows():\n",
    "    print(f\"\\nTitle: {post['title']}\")\n",
    "    print(f\"Subreddit: r/{post['subreddit']}\")\n",
    "    print(f\"Score: {post['score']:,} | Comments: {post['comments']:,}\")\n",
    "    print(f\"Posted: {post['created_utc']}\")\n",
    "    print(f\"URL: {post['url']}\")\n",
    "    print(f\"Reddit Discussion: {post['reddit_url']}\")\n",
    "    if post['is_self'] and len(post['text']) > 200:\n",
    "        print(f\"Text Preview: {post['text'][:200]}...\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Save results to CSV\n",
    "filename = f\"reddit_search_{query.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "results.to_csv(filename, index=False)\n",
    "print(f\"\\nResults saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "class BingNewsAPI():\n",
    "    \"\"\"Client for Bing News Search API\"\"\"\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.session = requests.Session()\n",
    "\n",
    "        self.base_url = \"https://api.bing.microsoft.com/v7.0/news/search\"\n",
    "        self.session.headers.update({\n",
    "            'Ocp-Apim-Subscription-Key': self.api_key\n",
    "        })\n",
    "\n",
    "    def search_news(self, query: str, count: int = 10) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Search news articles using Bing News API\n",
    "        \n",
    "        Args:\n",
    "            query: Search term\n",
    "            count: Number of results to return (max 100)\n",
    "            \n",
    "        Returns:\n",
    "            List of news articles\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            'q': query,\n",
    "            'count': min(count, 100),\n",
    "            'freshness': 'Day'\n",
    "        }\n",
    "        \n",
    "        response = self.session.get(self.base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        results = response.json()\n",
    "        return results.get('value', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import logging\n",
    "import asyncio\n",
    "import platform\n",
    "import nest_asyncio\n",
    "from typing import List, Dict, Set\n",
    "\n",
    "import certifi\n",
    "import aiohttp\n",
    "from bs4 import BeautifulSoup\n",
    "from aiohttp import ClientTimeout\n",
    "from fake_useragent import UserAgent\n",
    "from aiohttp_retry import RetryClient, ExponentialRetry\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "class FastNewsScraper:\n",
    "    \"\"\"Asynchronous news content scraper optimized for speed\"\"\"\n",
    "    \n",
    "    def __init__(self, max_concurrent: int = 50, timeout: int = 10):\n",
    "        self.max_concurrent = max_concurrent\n",
    "        self.timeout = ClientTimeout(total=timeout)\n",
    "        self.ua = UserAgent()\n",
    "        self.seen_urls: Set[str] = set()\n",
    "        \n",
    "        # Configure logging\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Setup SSL context\n",
    "        self.ssl_context = ssl.create_default_context(cafile=certifi.where())\n",
    "\n",
    "    def _get_random_headers(self) -> Dict[str, str]:\n",
    "        \"\"\"Generate random headers for each request\"\"\"\n",
    "        return {\n",
    "            'User-Agent': self.ua.random,\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "\n",
    "    async def _extract_content(self, html: str) -> Dict[str, str]:\n",
    "        \"\"\"Extract content from HTML using BeautifulSoup with minimal parsing\"\"\"\n",
    "        try:\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            \n",
    "            # Quick removal of unnecessary elements\n",
    "            for tag in soup(['script', 'style', 'nav', 'footer', 'iframe', 'aside']):\n",
    "                tag.decompose()\n",
    "            \n",
    "            # Fast content extraction using common patterns\n",
    "            content = {\n",
    "                'title': '',\n",
    "                'text': '',\n",
    "                'metadata': {}\n",
    "            }\n",
    "            \n",
    "            # Quick title extraction\n",
    "            title_tag = (\n",
    "                soup.find('h1') or \n",
    "                soup.find('meta', property='og:title') or\n",
    "                soup.find('title')\n",
    "            )\n",
    "            if title_tag:\n",
    "                content['title'] = title_tag.get_text() if hasattr(title_tag, 'get_text') else title_tag.get('content', '')\n",
    "            \n",
    "            # Quick main content extraction\n",
    "            article_tag = (\n",
    "                soup.find('article') or\n",
    "                soup.find('div', class_=['article-content', 'story-content', 'post-content']) or\n",
    "                soup.find('div', {'itemprop': 'articleBody'})\n",
    "            )\n",
    "            \n",
    "            if article_tag:\n",
    "                # Extract text efficiently\n",
    "                paragraphs = article_tag.find_all('p')\n",
    "                content['text'] = '\\n'.join(p.get_text(strip=True) for p in paragraphs)\n",
    "            \n",
    "            return content\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Content extraction error: {str(e)}\")\n",
    "            return {'title': '', 'text': '', 'metadata': {}}\n",
    "\n",
    "    async def _fetch_url(self, session: aiohttp.ClientSession, url: str) -> Dict[str, str]:\n",
    "        \"\"\"Fetch and process a single URL\"\"\"\n",
    "        try:\n",
    "            retry_options = ExponentialRetry(attempts=2)\n",
    "            retry_client = RetryClient(client_session=session, retry_options=retry_options)\n",
    "            \n",
    "            async with retry_client.get(\n",
    "                url,\n",
    "                headers=self._get_random_headers(),\n",
    "                timeout=self.timeout,\n",
    "                ssl=self.ssl_context\n",
    "            ) as response:\n",
    "                if response.status == 200:\n",
    "                    html = await response.text()\n",
    "                    content = await self._extract_content(html)\n",
    "                    content['url'] = url\n",
    "                    content['status'] = 'success'\n",
    "                    return content\n",
    "                else:\n",
    "                    return {'url': url, 'status': 'error', 'error': f'HTTP {response.status}'}\n",
    "                    \n",
    "        except asyncio.TimeoutError:\n",
    "            return {'url': url, 'status': 'error', 'error': 'timeout'}\n",
    "        except Exception as e:\n",
    "            return {'url': url, 'status': 'error', 'error': str(e)}\n",
    "\n",
    "    async def scrape_urls(self, urls: List[str]) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Scrape multiple URLs concurrently\n",
    "        \n",
    "        Args:\n",
    "            urls: List of URLs to scrape\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing scraped content\n",
    "        \"\"\"\n",
    "        # Remove duplicates and already seen URLs\n",
    "        unique_urls = list(set(urls) - self.seen_urls)\n",
    "        self.seen_urls.update(unique_urls)\n",
    "        \n",
    "        if not unique_urls:\n",
    "            return []\n",
    "        \n",
    "        # Create connection pool\n",
    "        conn = aiohttp.TCPConnector(\n",
    "            limit=self.max_concurrent,\n",
    "            ttl_dns_cache=300,\n",
    "            ssl=self.ssl_context\n",
    "        )\n",
    "        \n",
    "        async with aiohttp.ClientSession(connector=conn) as session:\n",
    "            tasks = [\n",
    "                self._fetch_url(session, url)\n",
    "                for url in unique_urls\n",
    "            ]\n",
    "            \n",
    "            # Use semaphore to limit concurrent requests\n",
    "            semaphore = asyncio.Semaphore(self.max_concurrent)\n",
    "            async def bounded_fetch(task):\n",
    "                async with semaphore:\n",
    "                    return await task\n",
    "            \n",
    "            # Gather results with timeout\n",
    "            results = await asyncio.gather(\n",
    "                *(bounded_fetch(task) for task in tasks),\n",
    "                return_exceptions=True\n",
    "            )\n",
    "            \n",
    "            # Filter out failures and exceptions\n",
    "            valid_results = [\n",
    "                result for result in results\n",
    "                if isinstance(result, dict) and result.get('status') == 'success'\n",
    "            ]\n",
    "            \n",
    "            return valid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_batch(urls: List[str], max_concurrent: int = 50, timeout: int = 10) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Synchronous wrapper for async scraping\n",
    "    \n",
    "    Args:\n",
    "        urls: List of URLs to scrape\n",
    "        max_concurrent: Maximum number of concurrent requests\n",
    "        timeout: Timeout in seconds for each request\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing scraped content\n",
    "    \"\"\"\n",
    "    scraper = FastNewsScraper(max_concurrent=max_concurrent, timeout=timeout)\n",
    "    \n",
    "    # Create new event loop\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "    except RuntimeError:\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "    \n",
    "    try:\n",
    "        results = loop.run_until_complete(scraper.scrape_urls(urls))\n",
    "    finally:\n",
    "        # Clean up\n",
    "        if platform.system() != 'Windows':  # Windows has issues with loop cleanup\n",
    "            loop.close()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_news_api = BingNewsAPI(os.getenv('BING_API_KEY'))\n",
    "bing_data = bing_news_api.search_news('AI trends', 5)\n",
    "bing_data_df = pd.DataFrame(bing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = FastNewsScraper(max_concurrent=5, timeout=10)\n",
    "\n",
    "# Create new event loop\n",
    "try:\n",
    "    loop = asyncio.get_event_loop()\n",
    "except RuntimeError:\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "\n",
    "try:\n",
    "    results = loop.run_until_complete(scraper.scrape_urls(bing_data_df.url.tolist()))\n",
    "finally:\n",
    "    # Clean up\n",
    "    if platform.system() != 'Windows':  # Windows has issues with loop cleanup\n",
    "        loop.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been saved in the directory: ../data/raw/news/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Sample list of dictionaries\n",
    "data = results\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"../data/raw/news/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to clean title and create a valid filename\n",
    "def clean_title(title):\n",
    "    # Replace non-alphanumeric characters with underscores\n",
    "    clean_name = re.sub(r'[^\\w\\s]', '', title)  # Remove special characters\n",
    "    clean_name = re.sub(r'\\s+', '_', clean_name.strip())  # Replace spaces with underscores\n",
    "    return clean_name\n",
    "\n",
    "# Write each dictionary to a .txt file\n",
    "for item in data:\n",
    "    filename = clean_title(item['title']) + \".txt\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    with open(filepath, 'w', encoding='utf-8') as file:\n",
    "        file.write(item['text'])\n",
    "\n",
    "print(f\"Files have been saved in the directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Lately: The year’s biggest YouTube trends, AI weather forecasts and brain rot',\n",
       "  'text': 'Welcome back to Lately, The Globe’s weekly tech newsletter. If you have feedback or just want to say hello to a real-life human,send me an e-mail.\\n\\U0001fae0 ‘Brain rot’ is the word of the year\\n👩🏻\\u200d💻 The biggest YouTubetrends in 2024\\n🖼️ Can an AI-generated image be copyrighted?\\n✂️ The future of the online harms bill\\nYou know that feeling of defeat or ashamed boredom that comes when you’re scrolling mindlessly online, and you’re viewing scores of sloppy, AI-generated memes, unhinged TikTok livestreams or posts of strangers fighting on Facebook? There’s a word for that feeling: brain rot.\\nThe Oxford University Press dubbedthe evocative phrase the word of the year, noting it “gained new prominence in 2024.” Oxford defines brain rot as “the supposed deterioration of a person’s mental or intellectual state, especially viewed as the result of overconsumption of material (now particularly online content) considered to be trivial or unchallenging.” “Brain rot” was chosen by a combination of public vote and language analysis by Oxford lexicographers. It beat five other finalists: demure, slop, dynamic pricing, romantasy and lore.\\nThe photo on the left was used to create the image on the right using an AI image generator.Supplied\\nIn Canada’s copyright database, you’ll find an image of a blurry, Van Gogh-esque sunset titledSuryast. It’s registered under two authors, Ankit Sahni and the RAGHAV Artificial Intelligence Painting App, the program Sahni used to create the image. For some, this is a problem. A legal clinic at the University of Ottawa is trying to expunge the registration, arguing that only humans can be authors.As Joe Castaldo reports, the rise of generative AI has brought up many thorny questions, including if AI-generated content deserves copyright protection and how much human involvement is required. These very questions are what inspired Sahni, who is an IP lawyer, to createSuryastin the first place, launching a consequential debate about copyright in the age of generative AI.\\nBack in September, the federal government introduced the online harms bill, a law that aimed to combat online child abuse and hate crime by making changes to Canada’s criminal code and putting the onus on platforms to remove harmful content. The legislation faced criticism from Conservatives who said the bill amounted to censorship, and it’s been held up by filibustering in the House of Commons.\\nNow, in an effort to pass the bill before a potential federal election,the Liberals are splitting the bill: the first bill would focus on kids’ safety and the second bill would include the new online hate-crime penalties. Child safety advocates, including Carol Todd, the mother of Amanda Todd who died by suicide after falling victim to cyberbullying, have been calling on MPs to end the filibuster and pass the bill. But even though the bill is now split from the contentious hate-crime measures, the Conservatives have indicated they’re still unlikely to support the legislation.\\nDeepMind, Google’s AI offshoot, claims its new tool GenCast canoutperform the world’s best weather predicting model, devising 15-day forecasts faster and more accurately.In a new study published inNature, DeepMind reports that in a comparative test between GenCast and the European Center for Medium-Range Weather Forecasts – the premier service that 35 countries around the world rely on to produce their own forecasts – the AI agent was more accurate 97.2 per cent of the time. Accurately predicting the weather could have major benefits: A University of Arizona study from last year found that making forecasts 50 per cent more accurate would save 2,200 lives a year in the U.S., primarily from extreme heat or cold.\\nCompanies in Mexico embrace AI to resurrect the dead(Rest of World)\\nStop using generative AI as a search engine(The Verge)\\nTrans Americans are turning to TikTok to crowdfund their relocations(Wired)\\nSupplied\\nFilterworld by Kyle Chayka, $37.99\\nThis week the Globe’s art section rounded upthe most giftable booksfor everyone on your list, including “the extremely online” person. One of the books they suggest isFilterworldby Kyle Chayka, a New Yorker staff writer who reports on internet culture and technology. In this non-fiction book, he explores how algorithmic feeds have homogenized how we create and consume culture, making it less interesting and fulfilling. Sure, it’s not the lightest read to curl up with next to the fire, but it’ll make you think deeply about how we spend our time online.\\nSabrina Carpenter performs in September.Brendan McDermid/Reuters\\nEvery December, online platforms release their year-in-review recaps, listing the top artists, influencers and trends of the previous 12 months. YouTube did something a bit differently this year. Rather than listing the most-watched videos of the year, it identified the top trending topics, based on an analysis including the number of views, uploads and activity by creators. This new methodology reflects the nature of YouTube: People aren’t just watching their favourite creators on the platform. They’re making their own reaction videos, posting commentary and making mash-ups, becoming content creators themselves in the process.\\nThis year’s top trending topicswere a mix of video games, niche animated series and big news stories. The only celebrity to make the list was pop star Sabrina Carpenter, who had a breakthrough with her single Espresso, and there was only one reference to Hollywood–blockbusterDeadpool & Wolverine. This shows how YouTube nurtures entertainment outside of the pop culture mainstream, but also how traditional media is becoming less influential in our online spaces.',\n",
       "  'metadata': {},\n",
       "  'url': 'https://www.theglobeandmail.com/business/article-lately-the-years-biggest-youtube-trends-ai-weather-forecasts-and-brain/',\n",
       "  'status': 'success'},\n",
       " {'title': '8 Game-Changing Manufacturing Trends That Will Define 2025',\n",
       "  'text': \"The manufacturing sector is no stranger to innovation. In fact, it’s always been at the forefront of digital transformation, taking the arrival of robotics, the internet and new developments in material science in its stride.\\nHowever, in 2025, it still finds itself braced for disruption, as manufacturers around the world grapple with the implications of artificial intelligence. There’s also the growing importance of improving sustainability as the climate crisis deepens and building resilience in the face of political and societal uncertainty.\\nIn order to meet these challenges, the companies responsible for creating products we use every day are enthusiastically investing in breakthrough technologies as well as adapting to cultural changes, such as the need to rethink skills and training.\\nSo let’s take a look at how this will unfold over the next year by overviewing the key trends and opportunities:\\nIn 2025, we will see manufacturers rolling out many use cases for generative AI designed to speed up and drive efficiency in manufacturing processes. By leveraging the power of generative design, it will be possible to create stronger, lighter components that make more efficient use of available materials. We’ve already seen aerospace companies leveraging genAI to create newaircraft parts, and automotive manufacturers are using it to optimize vehicle designs. I believe we will see many more innovative use cases in the coming year as manufacturers increasingly integrate genAI into their operations.\\nRobots are not new in manufacturing; in fact, robots have been working in factories for more than 50 years. What is new, however, is the new generation of intelligent robots that are able to work safely and effectively alongside humans, apply themselves to different tasks, and learn to become more efficient at their jobs and navigating their environments. As robots move away from the assembly line andinto the workforce, humans will develop new skills around leading and interacting with automated co-workers – sometimes referred to as “cobots”.\\nPositioning a business asa leaderrather than simply a follower or even a laggard in the AI era will become a growing priority for many manufacturing companies. Put simply, it’s no longer good enough to simply adopt new technologies like robotics, predictive maintenance and automation. As the barriers to entry continue to fall, it has to be done in a way that’s more innovative, effective and efficient than the competition. Developing the capacity not just to follow trends but to identify opportunities to blaze a trail will increasingly become a priority in 2025.\\nThere are numerous reasons why sustainability is quickly becoming a business priority for manufacturers in 2025. They include consumer demand, stricter regulations and the simple fact that we’re increasingly seeing the impact of climate disruption in the world around us. Due to this, we can expect to see a strategic switch towards cleaner and greener operations, such as the use of renewable energy, recyclable materials, reductions in emissions, excessive packaging, and water use.\\nThere’s a widely-acknowledged skills crisis among industries hoping to reap the opportunities offered by AI, robotics, advanced data analytics and automation. Bridging this skills gap will require manufacturers to rethink the way they hire and train staff, and for many, this will become a critical business priority in 2025. Addressing this challenge may involve investing in upskilling and reskilling, developing apprenticeship programs or forging new relationships with educators and academia.\\nThis year, smartphone manufacturer Xiaomiswitched onits fully autonomous dark factory close to Beijing, capable of producing 10 million handsets a year without human intervention. This model will become increasingly common as manufacturers chase improved efficiency, sustainability and reduced waste. While “lights out” factories have been around for a while, Xiaomi’s factory is the first that is able to learn how to operate more efficiently and optimize its own processes thanks to its AI-powered “brain”.\\nThere can undoubtedly be cultural barriers to AI adoption. Some people are worried it will replace them or make them redundant, while others believe that decision-making shouldn't be left to machines. While these are all valid concerns, identifying areas where AI can clearly solve problems or create efficiencies while mitigating its potential for causing harm will be a priority for the manufacturing industry in 2025. This will include planning and delivering initiativesfostering an understandingof AI across a workforce and ensuring its benefits are felt by all.\\nThe logistical challenges around sourcing components and managing complex inventories and production infrastructure are perfectly suited to automated, intelligent solutions. AI-powered tools leveraging real-time data analytics will enable more accurate demand forecasting and automated decision-making, helping manufacturers to build supply chains that are more resilient and adaptive to changing market conditions. In 2025, AI will enable manufacturers to anticipate disruption more effectively and identify opportunities to improve efficiency, ultimately leading to improved customer experience and business performance.\\nAs we move through 2025, the manufacturing sector stands at a pivotal moment of transformation. While challenges around AI adoption, sustainability, and workforce development remain significant, the convergence of smart technologies, automated systems, and sustainable practices is creating unprecedented opportunities for innovation. Companies that successfully navigate these changes – embracing AI-driven efficiency while building resilient, sustainable operations and investing in their workforce – will be best positioned to thrive in manufacturing's next era. The future of manufacturing isn't just about automation and AI – it's about creating smarter, more sustainable, and more adaptive production systems that can meet the challenges of tomorrow.\\n\\nOne Community. Many Voices.\\xa0Create a free account to share your thoughts.\\nOur community is about connecting people through open and thoughtful conversations. We want our readers to share their views and exchange ideas and facts in a safe space.\\nIn order to do so, please follow the posting rules in our site'sTerms of Service.We've summarized some of those key rules below. Simply put, keep it civil.\\nYour post will be rejected if we notice that it seems to contain:\\nUser accounts will be blocked if we notice or believe that users are engaged in:\\nSo, how can you be a power user?\\nThanks for reading our community guidelines.  Please read the full list of posting rules found in our site'sTerms of Service.\",\n",
       "  'metadata': {},\n",
       "  'url': 'https://www.forbes.com/sites/bernardmarr/2024/12/06/8-game-changing-manufacturing-trends-that-will-define-2025/',\n",
       "  'status': 'success'},\n",
       " {'title': '\\nDeep Dive: AI 2024\\n',\n",
       "  'text': \"In this issue, we delve into the transformative impact of AI on healthcare and pharma, featuring insights on key AI trends from the floor of Frontiers Health, the ongoing battle against drift, and the promise of biological software. Plus, we explore AI's role in drug discovery, commercialisation, and medical information, and take an in-depth look at why drugs fail.\\nDecoding the future: Key AI trends and innovations at Frontiers Health:From patient autonomy to repurposed drugs, Frontiers Health 2024 showcased the transformative potential of AI in healthcare. Here, we explore five key trends and innovations that caught our attention at this year’s event.\\nPharma and the ongoing battle against AI drift:Addressing the challenge of AI drift is critical for maintaining the reliability and effectiveness of AI systems in pharma. To find out more, Pharmaphorum web editor, Nicole Raleigh, examines how companies are navigating algorithmic shifts that threaten operational accuracy.\\nBig interview: Inceptive's Jakob Uszkoreit on the promise of biological software:In an exclusive interview, deep learning pioneer, Jakob Uszkoreit, shares his journey from groundbreaking success at Google to the uncharted territory of biological software, and discusses how AI is bridging biology and computation for faster, more effective breakthroughs\\nFrom R&D to ROI: AI’s impact on pharma commercialisationAI is transforming R&D ROI by accelerating drug discovery timelines and optimising resource allocation. Here, EVERSANA’s, Scott Snyder, explores how AI-powered analytics are enhancing market access and commercialisation strategies.\\nRight to reply: ChatGPT and AI in healthcareMuch has been said about the potential (both good and bad) of AI in healthcare. But, to get both sides of the story, and uncover the true intentions of GenAI, Deep Dive sat down with the notorious player that sparked the current hype cycle: Chat-GPT.\\nWhy drugs fail: The unrelenting challenge of finding new drugsDespite advances in technology, drug failure remains a significant hurdle for the industry. Jordan Lane, co-founder and CSO for Ignota Labs, breaks down the scientific and structural barriers that contribute to high drug failure rates and explores how AI may help to address them.\\nA strategic framework for evaluating AI in drug discovery:Evaluating AI’s effectiveness in drug discovery requires a robust and strategic framework. Here, L.E.K. Consulting provides a roadmap for assessing AI tools, ensuring they align with scientific and commercial goals.\\nNavigating the evolving landscape of medical information with AI-powered solutionsIQVIA’s Simon Johns breaks down how AI-powered solutions are reshaping the way medical information is processed and delivered, improving accessibility and accuracy. Learn about the technologies driving this shift and their implications for the future of medical communication.\\nRead Deep Dive:AI 2024in full pharmaphorum’s digital magazineDeep Diveprovides objective, issue-driven views, analysis, high-level interviews and unique research for pharmaceutical companies, biotech firms and the wider healthcare sector. Subscribe tofuture issues of Deep Dive.\",\n",
       "  'metadata': {},\n",
       "  'url': 'https://pharmaphorum.com/digital/deep-dive-ai-2024',\n",
       "  'status': 'success'},\n",
       " {'title': 'How AI can help you attract, engage and retain the best talent in 2025',\n",
       "  'text': 'Worawut - stock.adobe.com\\nAs we move into 2025, the landscape of human resources (HR) is heading for a significant transformation.Artificial intelligence(AI) is set to revolutionise workforce collaboration, efficiency, and talent management.\\nFor HR leaders, harnessing the power of AI will be essential toattract, engage, and retain top talentin an increasingly competitive market.\\nAI is reshaping and revamping HRby automating routine and mundane tasks such as interview scheduling, data entry, and CV screenings. This automation allows HR teams to focus on strategic initiatives that add real value to employees, such as developing diverse cultures, offering tailored development programmes, and increasing engagement.\\nAI-powered analytics can identify workforce trends, predict employee turnover, and suggest to retain top talent. These insights enable HR leaders to make data-driven decisions to support a high-performance culture, ultimately improving employee engagement and organisational performance.\\nJust look at Unilever, which uses AI to streamline its recruitment process. By using AI-driven assessments and video interview analytics, Unilever has significantly reduced time-to-hire while enhancing the candidate experience. Additionally, AI can streamline performance management by providing continuous feedback and personalised development plans. This shift towards real-time performance management fosters a culture of continuous improvement, where the team receives timely feedback and support to achieve their goals, leading to higher engagement levels and better retention rates.\\nAs the demand on sourcing talent with scarce skills continues in 2025, attracting top talent needs innovative strategies. AI can play a pivotal role in enhancing the candidate experience. Imagine AI-driven chatbots engaging with candidates in real-time, answering their questions and providing personalised information about the company and the role. This immediate engagement can significantly improve the candidate experience, making the organisation more attractive.\\nAI can also help create a more inclusive hiring processes by eliminating unconscious biases from recruitment. AI algorithms can analyse job descriptions to ensure they are free from biased language and assess candidates based on objective criteria. This is an incredibly important step to support organisations in attracting and growing a more diverse and inclusive workforce, which is crucial for driving innovation and business success.\\nRetaining your team is equally important as attracting it. AI can help HR leaders identify early signs of people’s disengagement or dissatisfaction. For instance, AI-powered sentiment analysis can monitor employee communications and flag any negative sentiments, allowing HR and managers to intervene proactively. By addressing issues before they escalate, organisations can improve the satisfaction, happiness and ultimately retention of the team.\\nAI can also facilitate personalised employee development. By analysing skills, performance data, and career aspirations, AI can recommend tailored development programmes and career paths for each individual. This personalised approach to development can help people feel valued and supported.\\n24% of all workersare worried that AI will soon make their job obsolete. HR leaders have a crucial role in addressing these concerns and ensuring their teams are ready for AI integration. Providing training and the right tools to integrate AI smoothly is essential. By fostering a culture of continuous improvement and responsible AI use, HR can drive greater efficiency and empower the entire workforce.\\nAI is more likely to enhance roles rather than replace them, and HR leaders should embrace AI ethically and transparently. This involves being clear about how AI is used, ensuring data privacy, and maintaining a human touch in all interactions. By doing so, HR can build trust and create a positive environment where AI is seen as a tool for empowerment rather than a threat.\\nAs we approach 2025 and beyond, the integration of AI in HR will continue to evolve. Future trends may include more sophisticated AI-driven talent management systems, enhanced predictive analytics for workforce planning, and even more personalised employee experiences powered by AI. HR leaders who stay ahead of these trends and continually innovate will be well-positioned to lead their organisations into the future.\\nLooking to the New Year, AI will play a pivotal role in enhancing HR functions, making them more efficient, strategic, and employee centric. By leveraging AI to attract, engage, and retain top talent, organisations can stay competitive in a rapidly evolving job market. HR leaders who embrace AI responsibly and proactively will be well-positioned to drive their organisations forward, creating workplaces that are both productive and fulfilling for their team.\\nToria Walters is chief people officer atANS, a digital transformation provider and Microsoft’s UK Services Partner of the Year 2024. Headquartered in Manchester, it offers public and private cloud, security, business applications, low code, and data services to thousands of customers, from enterprise to SMB and public sector organisations.',\n",
       "  'metadata': {},\n",
       "  'url': 'https://www.computerweekly.com/opinion/How-AI-can-help-you-attract-engage-and-retain-the-best-talent-in-2025',\n",
       "  'status': 'success'},\n",
       " {'title': 'At AWS Re:Invent, A Look At Reinventing AI',\n",
       "  'text': 'This year’s Amazon Web Services conference, re:Invent 2024, confirmed a few trends we’ve been tracking in the artificial intelligence boom. These include massive changes in the cloud infrastructure landscape with investment of hundreds of billions of dollars in an AI infrastructure arms race, as well as the struggle of enterprises to find return on investment in AI.\\nThis week, both of these trends had interesting twists. The week started off with the resignation of Intel CEO Pat Gelsinger, demonstrating what happens when you miss a huge market shift. Intel, even before Gelsinger took over, was poorly positioned in graphics processing units, the area that NVIDIA pioneered. But Gelsinger perhaps made things worse by focusing on an approach favoring the buildout of domestic and European manufacturing facilities and a foundry business, all based in part on government funding.\\nAWShad plenty of announcements in hardwareto demonstrate that it will stay in front of the AI arms race, including ensuring its supply of chips. In addition to buying chips from AI compute leaders NVIDIA and AMD, AWS has its own line of chips, including Graviton and Trainium. Here at re:Invent, it unveiled mass-scale AI clusters, complete with its own networking and interconnect technology, as well as general availability of its Trainium2 AI training chip.\\nLAS VEGAS, NEVADA - DECEMBER 3: Amazon Web Services (AWS) CEO Matt Garman delivers a keynote address... [+]during AWS re:Invent 2024, a conference hosted by Amazon Web Services, at The Venetian Las Vegas on December 3, 2024 in Las Vegas, Nevada. (Photo by Noah Berger/Getty Images for Amazon Web Services)\\nOn the enterprise ROI front, I saw several examples of this in the re:Invent keynotes as well as the analyst conference, where companies as diverse as Apple, JP Morgan, The Hartford, Novo Nordisk, and others demonstrated how they are using AI to gain ROI in specific use cases.\\nLet’s dive into these two areas in more detail.\\nWalking around the re:Invent conference, which hosted 60,000 people, you can talk to anybody from cloud engineers to Fortune 500 CEOs. The conference is of course owned and operated by AWS, so it’s an annual tradition for AWS to launch a barrage of technology announcements—literally hundreds—that demonstrate why it’s still the leading cloud operator.\\nThe question is, will AI help or hurt AWS in the long run? In addition to AWS competitors Microsoft Azure and Google Cloud, the AI boom has spawned a raft of AI-focused cloud providers, including Lambda and CoreWeave, the latter of which has achieved a valuation of tens of billions of dollars in just a few years.\\nAWS is of course determined not to let AI derail its leadership. Its announcements range from huge hardware projects to feature upgrades of its AI services SageMaker and Bedrock.\\nOn the hardware front, AWS showed it has a diversification strategy to provide its own hardware, even though it buys from many suppliers, including NVIDIA. AWS announced general availability of Amazon Elastic Compute Cloud (Amazon EC2) on Trn2 instances, which feature clusters of 16 Trn2 chips. And Trn2 can be scaled up using hardware clustering solutions. A separate Trn2 UltraServer, now in preview, features a cluster of 64 Trn2 chips across four Trn2 instances.\\nAWS CEO Matt Garman positioned it as a broadening of the market rather than as a competitive alternative to NVIDIA.\\n\"NVIDIA is an incredibly important partner of ours. AMD is an incredible partner as well. Today it is true that the vast majority of workloads run on NVIDIA. We\\'re so early where GenAI can be, that I think Trainium increases the size of the pie. It\\'s not going to be at the expense [of others].\"\\n\\nThe company is also planning a massive supercomputer named Project Rainier in partnership with Anthropic (which AWS has invested in), based on UltraServers. It\\'s set to debut in 2025. Anthropic isn’t alone. Other Trn2customers includeDatabricks, Datadog, Ricoh, Hugging Face, and PyTorch.\\nIt wouldn’t be re:Invent without lots of geeky upgrades to AWS services. AWS has rebranded its SageMaker ML service as SageMaker AI, which sports a bunch of enhancements designed to grease the wheels of ML-based analytics. These include the SageMaker HyperPod, whichcoordinates modeling workloads.\\nIn a keynote talk at the conference this week, Swami Sivasubramanian, VP of AI and data at AWS, outlined a raft of new services that streamline model training and inferencing for enterprise customers.\\n“We’re seeing the convergence of big data, analytics, machine learning, and generative AI,” said Sivasubramanian. And AWS has built on a range of past successes to meet demand, he said.\\nIn another example, the company’s other AI service, Bedrock, offers a range of large language models. This year featuresmulti-agent collaboration, which allows agents to coordinate across different tasks. Example: For a financial services firm, according to AWS’s online announcement, “specialized agents could coordinate to gather data, analyze trends, and provide actionable recommendations—working in parallel to improve response times and precision.” This feature is currently available in the US East (N. Virginia), US West (Oregon), and Europe (Ireland) AWS Regions.\\nQueue up the next topic: enterprise AI. The world is filled with chatter about whether AI can fulfill its promise in delivering ROI to the enterprise.\\nThere are of course many skeptics, including Render founder and CEO Anurag Goel, who was also a former executive at Stripe. Render has a cloud automation platform that Goel says is being adopted by “hundreds of thousands of developers per month.” He told me that he hadn’t seen a huge demonstration of ROI at the conference.\\n“AWS announced a lot of services around AI but they lack a coherent end-to-end theme,” Goel told me in the hallway of the Venetian. “The business value and the ROI remains unclear.”\\nDespite some skepticism about the AI endgame, some attendees said there has been a shift in thinking from “god” products to more tactical technology using AI. Adam Jacob, cofounder and CEO of System Initiative, told me the new thinking embodies a more tactical, focused approach he refers to as “micro AI.”\\n“As an industry, we started out by thinking, ‘We\\'re going to have a single god robot that we just pump all the exabytes of data to and we just let the god machine sort it out.’ We\\'re learning that that creates a terrible user experience and is incredibly hard to track and secure. Instead, we\\'re starting to build micro AI experiences that form a series of small experiences that build up to really compelling big ones.\"\\nThe case for micro AI makes sense. Generalized AI is difficult and has key challenges such as accuracy, data security, and data provenance. But if you can focus on specific solutions with an AI tool, you might have a better shot at ROI gratification.\\nIn its analyst conference, AWS did a good job of presenting ROI examples from customers, which was a noticeable change from last year, when the market was still riding the pink cloud of AI hype.\\nIn its briefing sessions for industry analysts, AWS had examples of compelling ROI-driven case studies. Companies presenting included Apple, JP Morgan, The Hartford, Merck, New York Life, and Novo Nordisk, among others.\\nLouise Lind Skov, head of content digitalisation with Danish pharmaceutical giant Novo Nordisk. showed how the company reduced the time to create regulatory documentation from two months to several minutes by building its own AI-driven tool on AWS, which it calls NovoScribe.\\n“From a medical writing perspective, this would have required thousands of hours of work,” said Skov.\\nNovoScribe seems to be a great example of micro AI. By focusing on a specific use case and process, Novo Nordisk was able to deliver specific efficiencies.\\nThis will be a big theme going forward as the AI wave takes a circuitous path to technology nirvana. Nobody has a god AI app yet, but there are certainly many tools available to solve everyday problems and deliver tangible results in focused areas.\\n\\nOne Community. Many Voices.\\xa0Create a free account to share your thoughts.\\nOur community is about connecting people through open and thoughtful conversations. We want our readers to share their views and exchange ideas and facts in a safe space.\\nIn order to do so, please follow the posting rules in our site\\'sTerms of Service.We\\'ve summarized some of those key rules below. Simply put, keep it civil.\\nYour post will be rejected if we notice that it seems to contain:\\nUser accounts will be blocked if we notice or believe that users are engaged in:\\nSo, how can you be a power user?\\nThanks for reading our community guidelines.  Please read the full list of posting rules found in our site\\'sTerms of Service.',\n",
       "  'metadata': {},\n",
       "  'url': 'https://www.forbes.com/sites/rscottraynovich/2024/12/06/at-aws-reinvent-a-look-at-reinventing-ai/',\n",
       "  'status': 'success'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [{'title': 'Lately: The year’s biggest YouTube trends, AI weather forecasts and brain rot',\n",
    "  'text': 'Welcome back to Lately, The Globe’s weekly tech newsletter. If you have feedback or just want to say hello to a real-life human,send me an e-mail.\\n\\U0001fae0 ‘Brain rot’ is the word of the year\\n👩🏻\\u200d💻 The biggest YouTubetrends in 2024\\n🖼️ Can an AI-generated image be copyrighted?\\n✂️ The future of the online harms bill\\nYou know that feeling of defeat or ashamed boredom that comes when you’re scrolling mindlessly online, and you’re viewing scores of sloppy, AI-generated memes, unhinged TikTok livestreams or posts of strangers fighting on Facebook? There’s a word for that feeling: brain rot.\\nThe Oxford University Press dubbedthe evocative phrase the word of the year, noting it “gained new prominence in 2024.” Oxford defines brain rot as “the supposed deterioration of a person’s mental or intellectual state, especially viewed as the result of overconsumption of material (now particularly online content) considered to be trivial or unchallenging.” “Brain rot” was chosen by a combination of public vote and language analysis by Oxford lexicographers. It beat five other finalists: demure, slop, dynamic pricing, romantasy and lore.\\nThe photo on the left was used to create the image on the right using an AI image generator.Supplied\\nIn Canada’s copyright database, you’ll find an image of a blurry, Van Gogh-esque sunset titledSuryast. It’s registered under two authors, Ankit Sahni and the RAGHAV Artificial Intelligence Painting App, the program Sahni used to create the image. For some, this is a problem. A legal clinic at the University of Ottawa is trying to expunge the registration, arguing that only humans can be authors.As Joe Castaldo reports, the rise of generative AI has brought up many thorny questions, including if AI-generated content deserves copyright protection and how much human involvement is required. These very questions are what inspired Sahni, who is an IP lawyer, to createSuryastin the first place, launching a consequential debate about copyright in the age of generative AI.\\nBack in September, the federal government introduced the online harms bill, a law that aimed to combat online child abuse and hate crime by making changes to Canada’s criminal code and putting the onus on platforms to remove harmful content. The legislation faced criticism from Conservatives who said the bill amounted to censorship, and it’s been held up by filibustering in the House of Commons.\\nNow, in an effort to pass the bill before a potential federal election,the Liberals are splitting the bill: the first bill would focus on kids’ safety and the second bill would include the new online hate-crime penalties. Child safety advocates, including Carol Todd, the mother of Amanda Todd who died by suicide after falling victim to cyberbullying, have been calling on MPs to end the filibuster and pass the bill. But even though the bill is now split from the contentious hate-crime measures, the Conservatives have indicated they’re still unlikely to support the legislation.\\nDeepMind, Google’s AI offshoot, claims its new tool GenCast canoutperform the world’s best weather predicting model, devising 15-day forecasts faster and more accurately.In a new study published inNature, DeepMind reports that in a comparative test between GenCast and the European Center for Medium-Range Weather Forecasts – the premier service that 35 countries around the world rely on to produce their own forecasts – the AI agent was more accurate 97.2 per cent of the time. Accurately predicting the weather could have major benefits: A University of Arizona study from last year found that making forecasts 50 per cent more accurate would save 2,200 lives a year in the U.S., primarily from extreme heat or cold.\\nCompanies in Mexico embrace AI to resurrect the dead(Rest of World)\\nStop using generative AI as a search engine(The Verge)\\nTrans Americans are turning to TikTok to crowdfund their relocations(Wired)\\nSupplied\\nFilterworld by Kyle Chayka, $37.99\\nThis week the Globe’s art section rounded upthe most giftable booksfor everyone on your list, including “the extremely online” person. One of the books they suggest isFilterworldby Kyle Chayka, a New Yorker staff writer who reports on internet culture and technology. In this non-fiction book, he explores how algorithmic feeds have homogenized how we create and consume culture, making it less interesting and fulfilling. Sure, it’s not the lightest read to curl up with next to the fire, but it’ll make you think deeply about how we spend our time online.\\nSabrina Carpenter performs in September.Brendan McDermid/Reuters\\nEvery December, online platforms release their year-in-review recaps, listing the top artists, influencers and trends of the previous 12 months. YouTube did something a bit differently this year. Rather than listing the most-watched videos of the year, it identified the top trending topics, based on an analysis including the number of views, uploads and activity by creators. This new methodology reflects the nature of YouTube: People aren’t just watching their favourite creators on the platform. They’re making their own reaction videos, posting commentary and making mash-ups, becoming content creators themselves in the process.\\nThis year’s top trending topicswere a mix of video games, niche animated series and big news stories. The only celebrity to make the list was pop star Sabrina Carpenter, who had a breakthrough with her single Espresso, and there was only one reference to Hollywood–blockbusterDeadpool & Wolverine. This shows how YouTube nurtures entertainment outside of the pop culture mainstream, but also how traditional media is becoming less influential in our online spaces.',\n",
    "  'metadata': {},\n",
    "  'url': 'https://www.theglobeandmail.com/business/article-lately-the-years-biggest-youtube-trends-ai-weather-forecasts-and-brain/',\n",
    "  'status': 'success'},\n",
    " {'title': '8 Game-Changing Manufacturing Trends That Will Define 2025',\n",
    "  'text': \"The manufacturing sector is no stranger to innovation. In fact, it’s always been at the forefront of digital transformation, taking the arrival of robotics, the internet and new developments in material science in its stride.\\nHowever, in 2025, it still finds itself braced for disruption, as manufacturers around the world grapple with the implications of artificial intelligence. There’s also the growing importance of improving sustainability as the climate crisis deepens and building resilience in the face of political and societal uncertainty.\\nIn order to meet these challenges, the companies responsible for creating products we use every day are enthusiastically investing in breakthrough technologies as well as adapting to cultural changes, such as the need to rethink skills and training.\\nSo let’s take a look at how this will unfold over the next year by overviewing the key trends and opportunities:\\nIn 2025, we will see manufacturers rolling out many use cases for generative AI designed to speed up and drive efficiency in manufacturing processes. By leveraging the power of generative design, it will be possible to create stronger, lighter components that make more efficient use of available materials. We’ve already seen aerospace companies leveraging genAI to create newaircraft parts, and automotive manufacturers are using it to optimize vehicle designs. I believe we will see many more innovative use cases in the coming year as manufacturers increasingly integrate genAI into their operations.\\nRobots are not new in manufacturing; in fact, robots have been working in factories for more than 50 years. What is new, however, is the new generation of intelligent robots that are able to work safely and effectively alongside humans, apply themselves to different tasks, and learn to become more efficient at their jobs and navigating their environments. As robots move away from the assembly line andinto the workforce, humans will develop new skills around leading and interacting with automated co-workers – sometimes referred to as “cobots”.\\nPositioning a business asa leaderrather than simply a follower or even a laggard in the AI era will become a growing priority for many manufacturing companies. Put simply, it’s no longer good enough to simply adopt new technologies like robotics, predictive maintenance and automation. As the barriers to entry continue to fall, it has to be done in a way that’s more innovative, effective and efficient than the competition. Developing the capacity not just to follow trends but to identify opportunities to blaze a trail will increasingly become a priority in 2025.\\nThere are numerous reasons why sustainability is quickly becoming a business priority for manufacturers in 2025. They include consumer demand, stricter regulations and the simple fact that we’re increasingly seeing the impact of climate disruption in the world around us. Due to this, we can expect to see a strategic switch towards cleaner and greener operations, such as the use of renewable energy, recyclable materials, reductions in emissions, excessive packaging, and water use.\\nThere’s a widely-acknowledged skills crisis among industries hoping to reap the opportunities offered by AI, robotics, advanced data analytics and automation. Bridging this skills gap will require manufacturers to rethink the way they hire and train staff, and for many, this will become a critical business priority in 2025. Addressing this challenge may involve investing in upskilling and reskilling, developing apprenticeship programs or forging new relationships with educators and academia.\\nThis year, smartphone manufacturer Xiaomiswitched onits fully autonomous dark factory close to Beijing, capable of producing 10 million handsets a year without human intervention. This model will become increasingly common as manufacturers chase improved efficiency, sustainability and reduced waste. While “lights out” factories have been around for a while, Xiaomi’s factory is the first that is able to learn how to operate more efficiently and optimize its own processes thanks to its AI-powered “brain”.\\nThere can undoubtedly be cultural barriers to AI adoption. Some people are worried it will replace them or make them redundant, while others believe that decision-making shouldn't be left to machines. While these are all valid concerns, identifying areas where AI can clearly solve problems or create efficiencies while mitigating its potential for causing harm will be a priority for the manufacturing industry in 2025. This will include planning and delivering initiativesfostering an understandingof AI across a workforce and ensuring its benefits are felt by all.\\nThe logistical challenges around sourcing components and managing complex inventories and production infrastructure are perfectly suited to automated, intelligent solutions. AI-powered tools leveraging real-time data analytics will enable more accurate demand forecasting and automated decision-making, helping manufacturers to build supply chains that are more resilient and adaptive to changing market conditions. In 2025, AI will enable manufacturers to anticipate disruption more effectively and identify opportunities to improve efficiency, ultimately leading to improved customer experience and business performance.\\nAs we move through 2025, the manufacturing sector stands at a pivotal moment of transformation. While challenges around AI adoption, sustainability, and workforce development remain significant, the convergence of smart technologies, automated systems, and sustainable practices is creating unprecedented opportunities for innovation. Companies that successfully navigate these changes – embracing AI-driven efficiency while building resilient, sustainable operations and investing in their workforce – will be best positioned to thrive in manufacturing's next era. The future of manufacturing isn't just about automation and AI – it's about creating smarter, more sustainable, and more adaptive production systems that can meet the challenges of tomorrow.\\n\\nOne Community. Many Voices.\\xa0Create a free account to share your thoughts.\\nOur community is about connecting people through open and thoughtful conversations. We want our readers to share their views and exchange ideas and facts in a safe space.\\nIn order to do so, please follow the posting rules in our site'sTerms of Service.We've summarized some of those key rules below. Simply put, keep it civil.\\nYour post will be rejected if we notice that it seems to contain:\\nUser accounts will be blocked if we notice or believe that users are engaged in:\\nSo, how can you be a power user?\\nThanks for reading our community guidelines.  Please read the full list of posting rules found in our site'sTerms of Service.\",\n",
    "  'metadata': {},\n",
    "  'url': 'https://www.forbes.com/sites/bernardmarr/2024/12/06/8-game-changing-manufacturing-trends-that-will-define-2025/',\n",
    "  'status': 'success'},\n",
    " {'title': '\\nDeep Dive: AI 2024\\n',\n",
    "  'text': \"In this issue, we delve into the transformative impact of AI on healthcare and pharma, featuring insights on key AI trends from the floor of Frontiers Health, the ongoing battle against drift, and the promise of biological software. Plus, we explore AI's role in drug discovery, commercialisation, and medical information, and take an in-depth look at why drugs fail.\\nDecoding the future: Key AI trends and innovations at Frontiers Health:From patient autonomy to repurposed drugs, Frontiers Health 2024 showcased the transformative potential of AI in healthcare. Here, we explore five key trends and innovations that caught our attention at this year’s event.\\nPharma and the ongoing battle against AI drift:Addressing the challenge of AI drift is critical for maintaining the reliability and effectiveness of AI systems in pharma. To find out more, Pharmaphorum web editor, Nicole Raleigh, examines how companies are navigating algorithmic shifts that threaten operational accuracy.\\nBig interview: Inceptive's Jakob Uszkoreit on the promise of biological software:In an exclusive interview, deep learning pioneer, Jakob Uszkoreit, shares his journey from groundbreaking success at Google to the uncharted territory of biological software, and discusses how AI is bridging biology and computation for faster, more effective breakthroughs\\nFrom R&D to ROI: AI’s impact on pharma commercialisationAI is transforming R&D ROI by accelerating drug discovery timelines and optimising resource allocation. Here, EVERSANA’s, Scott Snyder, explores how AI-powered analytics are enhancing market access and commercialisation strategies.\\nRight to reply: ChatGPT and AI in healthcareMuch has been said about the potential (both good and bad) of AI in healthcare. But, to get both sides of the story, and uncover the true intentions of GenAI, Deep Dive sat down with the notorious player that sparked the current hype cycle: Chat-GPT.\\nWhy drugs fail: The unrelenting challenge of finding new drugsDespite advances in technology, drug failure remains a significant hurdle for the industry. Jordan Lane, co-founder and CSO for Ignota Labs, breaks down the scientific and structural barriers that contribute to high drug failure rates and explores how AI may help to address them.\\nA strategic framework for evaluating AI in drug discovery:Evaluating AI’s effectiveness in drug discovery requires a robust and strategic framework. Here, L.E.K. Consulting provides a roadmap for assessing AI tools, ensuring they align with scientific and commercial goals.\\nNavigating the evolving landscape of medical information with AI-powered solutionsIQVIA’s Simon Johns breaks down how AI-powered solutions are reshaping the way medical information is processed and delivered, improving accessibility and accuracy. Learn about the technologies driving this shift and their implications for the future of medical communication.\\nRead Deep Dive:AI 2024in full pharmaphorum’s digital magazineDeep Diveprovides objective, issue-driven views, analysis, high-level interviews and unique research for pharmaceutical companies, biotech firms and the wider healthcare sector. Subscribe tofuture issues of Deep Dive.\",\n",
    "  'metadata': {},\n",
    "  'url': 'https://pharmaphorum.com/digital/deep-dive-ai-2024',\n",
    "  'status': 'success'},\n",
    " {'title': 'How AI can help you attract, engage and retain the best talent in 2025',\n",
    "  'text': 'Worawut - stock.adobe.com\\nAs we move into 2025, the landscape of human resources (HR) is heading for a significant transformation.Artificial intelligence(AI) is set to revolutionise workforce collaboration, efficiency, and talent management.\\nFor HR leaders, harnessing the power of AI will be essential toattract, engage, and retain top talentin an increasingly competitive market.\\nAI is reshaping and revamping HRby automating routine and mundane tasks such as interview scheduling, data entry, and CV screenings. This automation allows HR teams to focus on strategic initiatives that add real value to employees, such as developing diverse cultures, offering tailored development programmes, and increasing engagement.\\nAI-powered analytics can identify workforce trends, predict employee turnover, and suggest to retain top talent. These insights enable HR leaders to make data-driven decisions to support a high-performance culture, ultimately improving employee engagement and organisational performance.\\nJust look at Unilever, which uses AI to streamline its recruitment process. By using AI-driven assessments and video interview analytics, Unilever has significantly reduced time-to-hire while enhancing the candidate experience. Additionally, AI can streamline performance management by providing continuous feedback and personalised development plans. This shift towards real-time performance management fosters a culture of continuous improvement, where the team receives timely feedback and support to achieve their goals, leading to higher engagement levels and better retention rates.\\nAs the demand on sourcing talent with scarce skills continues in 2025, attracting top talent needs innovative strategies. AI can play a pivotal role in enhancing the candidate experience. Imagine AI-driven chatbots engaging with candidates in real-time, answering their questions and providing personalised information about the company and the role. This immediate engagement can significantly improve the candidate experience, making the organisation more attractive.\\nAI can also help create a more inclusive hiring processes by eliminating unconscious biases from recruitment. AI algorithms can analyse job descriptions to ensure they are free from biased language and assess candidates based on objective criteria. This is an incredibly important step to support organisations in attracting and growing a more diverse and inclusive workforce, which is crucial for driving innovation and business success.\\nRetaining your team is equally important as attracting it. AI can help HR leaders identify early signs of people’s disengagement or dissatisfaction. For instance, AI-powered sentiment analysis can monitor employee communications and flag any negative sentiments, allowing HR and managers to intervene proactively. By addressing issues before they escalate, organisations can improve the satisfaction, happiness and ultimately retention of the team.\\nAI can also facilitate personalised employee development. By analysing skills, performance data, and career aspirations, AI can recommend tailored development programmes and career paths for each individual. This personalised approach to development can help people feel valued and supported.\\n24% of all workersare worried that AI will soon make their job obsolete. HR leaders have a crucial role in addressing these concerns and ensuring their teams are ready for AI integration. Providing training and the right tools to integrate AI smoothly is essential. By fostering a culture of continuous improvement and responsible AI use, HR can drive greater efficiency and empower the entire workforce.\\nAI is more likely to enhance roles rather than replace them, and HR leaders should embrace AI ethically and transparently. This involves being clear about how AI is used, ensuring data privacy, and maintaining a human touch in all interactions. By doing so, HR can build trust and create a positive environment where AI is seen as a tool for empowerment rather than a threat.\\nAs we approach 2025 and beyond, the integration of AI in HR will continue to evolve. Future trends may include more sophisticated AI-driven talent management systems, enhanced predictive analytics for workforce planning, and even more personalised employee experiences powered by AI. HR leaders who stay ahead of these trends and continually innovate will be well-positioned to lead their organisations into the future.\\nLooking to the New Year, AI will play a pivotal role in enhancing HR functions, making them more efficient, strategic, and employee centric. By leveraging AI to attract, engage, and retain top talent, organisations can stay competitive in a rapidly evolving job market. HR leaders who embrace AI responsibly and proactively will be well-positioned to drive their organisations forward, creating workplaces that are both productive and fulfilling for their team.\\nToria Walters is chief people officer atANS, a digital transformation provider and Microsoft’s UK Services Partner of the Year 2024. Headquartered in Manchester, it offers public and private cloud, security, business applications, low code, and data services to thousands of customers, from enterprise to SMB and public sector organisations.',\n",
    "  'metadata': {},\n",
    "  'url': 'https://www.computerweekly.com/opinion/How-AI-can-help-you-attract-engage-and-retain-the-best-talent-in-2025',\n",
    "  'status': 'success'},\n",
    " {'title': 'At AWS Re:Invent, A Look At Reinventing AI',\n",
    "  'text': 'This year’s Amazon Web Services conference, re:Invent 2024, confirmed a few trends we’ve been tracking in the artificial intelligence boom. These include massive changes in the cloud infrastructure landscape with investment of hundreds of billions of dollars in an AI infrastructure arms race, as well as the struggle of enterprises to find return on investment in AI.\\nThis week, both of these trends had interesting twists. The week started off with the resignation of Intel CEO Pat Gelsinger, demonstrating what happens when you miss a huge market shift. Intel, even before Gelsinger took over, was poorly positioned in graphics processing units, the area that NVIDIA pioneered. But Gelsinger perhaps made things worse by focusing on an approach favoring the buildout of domestic and European manufacturing facilities and a foundry business, all based in part on government funding.\\nAWShad plenty of announcements in hardwareto demonstrate that it will stay in front of the AI arms race, including ensuring its supply of chips. In addition to buying chips from AI compute leaders NVIDIA and AMD, AWS has its own line of chips, including Graviton and Trainium. Here at re:Invent, it unveiled mass-scale AI clusters, complete with its own networking and interconnect technology, as well as general availability of its Trainium2 AI training chip.\\nLAS VEGAS, NEVADA - DECEMBER 3: Amazon Web Services (AWS) CEO Matt Garman delivers a keynote address... [+]during AWS re:Invent 2024, a conference hosted by Amazon Web Services, at The Venetian Las Vegas on December 3, 2024 in Las Vegas, Nevada. (Photo by Noah Berger/Getty Images for Amazon Web Services)\\nOn the enterprise ROI front, I saw several examples of this in the re:Invent keynotes as well as the analyst conference, where companies as diverse as Apple, JP Morgan, The Hartford, Novo Nordisk, and others demonstrated how they are using AI to gain ROI in specific use cases.\\nLet’s dive into these two areas in more detail.\\nWalking around the re:Invent conference, which hosted 60,000 people, you can talk to anybody from cloud engineers to Fortune 500 CEOs. The conference is of course owned and operated by AWS, so it’s an annual tradition for AWS to launch a barrage of technology announcements—literally hundreds—that demonstrate why it’s still the leading cloud operator.\\nThe question is, will AI help or hurt AWS in the long run? In addition to AWS competitors Microsoft Azure and Google Cloud, the AI boom has spawned a raft of AI-focused cloud providers, including Lambda and CoreWeave, the latter of which has achieved a valuation of tens of billions of dollars in just a few years.\\nAWS is of course determined not to let AI derail its leadership. Its announcements range from huge hardware projects to feature upgrades of its AI services SageMaker and Bedrock.\\nOn the hardware front, AWS showed it has a diversification strategy to provide its own hardware, even though it buys from many suppliers, including NVIDIA. AWS announced general availability of Amazon Elastic Compute Cloud (Amazon EC2) on Trn2 instances, which feature clusters of 16 Trn2 chips. And Trn2 can be scaled up using hardware clustering solutions. A separate Trn2 UltraServer, now in preview, features a cluster of 64 Trn2 chips across four Trn2 instances.\\nAWS CEO Matt Garman positioned it as a broadening of the market rather than as a competitive alternative to NVIDIA.\\n\"NVIDIA is an incredibly important partner of ours. AMD is an incredible partner as well. Today it is true that the vast majority of workloads run on NVIDIA. We\\'re so early where GenAI can be, that I think Trainium increases the size of the pie. It\\'s not going to be at the expense [of others].\"\\n\\nThe company is also planning a massive supercomputer named Project Rainier in partnership with Anthropic (which AWS has invested in), based on UltraServers. It\\'s set to debut in 2025. Anthropic isn’t alone. Other Trn2customers includeDatabricks, Datadog, Ricoh, Hugging Face, and PyTorch.\\nIt wouldn’t be re:Invent without lots of geeky upgrades to AWS services. AWS has rebranded its SageMaker ML service as SageMaker AI, which sports a bunch of enhancements designed to grease the wheels of ML-based analytics. These include the SageMaker HyperPod, whichcoordinates modeling workloads.\\nIn a keynote talk at the conference this week, Swami Sivasubramanian, VP of AI and data at AWS, outlined a raft of new services that streamline model training and inferencing for enterprise customers.\\n“We’re seeing the convergence of big data, analytics, machine learning, and generative AI,” said Sivasubramanian. And AWS has built on a range of past successes to meet demand, he said.\\nIn another example, the company’s other AI service, Bedrock, offers a range of large language models. This year featuresmulti-agent collaboration, which allows agents to coordinate across different tasks. Example: For a financial services firm, according to AWS’s online announcement, “specialized agents could coordinate to gather data, analyze trends, and provide actionable recommendations—working in parallel to improve response times and precision.” This feature is currently available in the US East (N. Virginia), US West (Oregon), and Europe (Ireland) AWS Regions.\\nQueue up the next topic: enterprise AI. The world is filled with chatter about whether AI can fulfill its promise in delivering ROI to the enterprise.\\nThere are of course many skeptics, including Render founder and CEO Anurag Goel, who was also a former executive at Stripe. Render has a cloud automation platform that Goel says is being adopted by “hundreds of thousands of developers per month.” He told me that he hadn’t seen a huge demonstration of ROI at the conference.\\n“AWS announced a lot of services around AI but they lack a coherent end-to-end theme,” Goel told me in the hallway of the Venetian. “The business value and the ROI remains unclear.”\\nDespite some skepticism about the AI endgame, some attendees said there has been a shift in thinking from “god” products to more tactical technology using AI. Adam Jacob, cofounder and CEO of System Initiative, told me the new thinking embodies a more tactical, focused approach he refers to as “micro AI.”\\n“As an industry, we started out by thinking, ‘We\\'re going to have a single god robot that we just pump all the exabytes of data to and we just let the god machine sort it out.’ We\\'re learning that that creates a terrible user experience and is incredibly hard to track and secure. Instead, we\\'re starting to build micro AI experiences that form a series of small experiences that build up to really compelling big ones.\"\\nThe case for micro AI makes sense. Generalized AI is difficult and has key challenges such as accuracy, data security, and data provenance. But if you can focus on specific solutions with an AI tool, you might have a better shot at ROI gratification.\\nIn its analyst conference, AWS did a good job of presenting ROI examples from customers, which was a noticeable change from last year, when the market was still riding the pink cloud of AI hype.\\nIn its briefing sessions for industry analysts, AWS had examples of compelling ROI-driven case studies. Companies presenting included Apple, JP Morgan, The Hartford, Merck, New York Life, and Novo Nordisk, among others.\\nLouise Lind Skov, head of content digitalisation with Danish pharmaceutical giant Novo Nordisk. showed how the company reduced the time to create regulatory documentation from two months to several minutes by building its own AI-driven tool on AWS, which it calls NovoScribe.\\n“From a medical writing perspective, this would have required thousands of hours of work,” said Skov.\\nNovoScribe seems to be a great example of micro AI. By focusing on a specific use case and process, Novo Nordisk was able to deliver specific efficiencies.\\nThis will be a big theme going forward as the AI wave takes a circuitous path to technology nirvana. Nobody has a god AI app yet, but there are certainly many tools available to solve everyday problems and deliver tangible results in focused areas.\\n\\nOne Community. Many Voices.\\xa0Create a free account to share your thoughts.\\nOur community is about connecting people through open and thoughtful conversations. We want our readers to share their views and exchange ideas and facts in a safe space.\\nIn order to do so, please follow the posting rules in our site\\'sTerms of Service.We\\'ve summarized some of those key rules below. Simply put, keep it civil.\\nYour post will be rejected if we notice that it seems to contain:\\nUser accounts will be blocked if we notice or believe that users are engaged in:\\nSo, how can you be a power user?\\nThanks for reading our community guidelines.  Please read the full list of posting rules found in our site\\'sTerms of Service.',\n",
    "  'metadata': {},\n",
    "  'url': 'https://www.forbes.com/sites/rscottraynovich/2024/12/06/at-aws-reinvent-a-look-at-reinventing-ai/',\n",
    "  'status': 'success'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome back to Lately, The Globe’s weekly tech newsletter. If you have feedback or just want to say hello to a real-life human,send me an e-mail.\n",
      "🫠 ‘Brain rot’ is the word of the year\n",
      "👩🏻‍💻 The biggest YouTubetrends in 2024\n",
      "🖼️ Can an AI-generated image be copyrighted?\n",
      "✂️ The future of the online harms bill\n",
      "You know that feeling of defeat or ashamed boredom that comes when you’re scrolling mindlessly online, and you’re viewing scores of sloppy, AI-generated memes, unhinged TikTok livestreams or posts of strangers fighting on Facebook? There’s a word for that feeling: brain rot.\n",
      "The Oxford University Press dubbedthe evocative phrase the word of the year, noting it “gained new prominence in 2024.” Oxford defines brain rot as “the supposed deterioration of a person’s mental or intellectual state, especially viewed as the result of overconsumption of material (now particularly online content) considered to be trivial or unchallenging.” “Brain rot” was chosen by a combination of public vote and language analysis by Oxford lexicographers. It beat five other finalists: demure, slop, dynamic pricing, romantasy and lore.\n",
      "The photo on the left was used to create the image on the right using an AI image generator.Supplied\n",
      "In Canada’s copyright database, you’ll find an image of a blurry, Van Gogh-esque sunset titledSuryast. It’s registered under two authors, Ankit Sahni and the RAGHAV Artificial Intelligence Painting App, the program Sahni used to create the image. For some, this is a problem. A legal clinic at the University of Ottawa is trying to expunge the registration, arguing that only humans can be authors.As Joe Castaldo reports, the rise of generative AI has brought up many thorny questions, including if AI-generated content deserves copyright protection and how much human involvement is required. These very questions are what inspired Sahni, who is an IP lawyer, to createSuryastin the first place, launching a consequential debate about copyright in the age of generative AI.\n",
      "Back in September, the federal government introduced the online harms bill, a law that aimed to combat online child abuse and hate crime by making changes to Canada’s criminal code and putting the onus on platforms to remove harmful content. The legislation faced criticism from Conservatives who said the bill amounted to censorship, and it’s been held up by filibustering in the House of Commons.\n",
      "Now, in an effort to pass the bill before a potential federal election,the Liberals are splitting the bill: the first bill would focus on kids’ safety and the second bill would include the new online hate-crime penalties. Child safety advocates, including Carol Todd, the mother of Amanda Todd who died by suicide after falling victim to cyberbullying, have been calling on MPs to end the filibuster and pass the bill. But even though the bill is now split from the contentious hate-crime measures, the Conservatives have indicated they’re still unlikely to support the legislation.\n",
      "DeepMind, Google’s AI offshoot, claims its new tool GenCast canoutperform the world’s best weather predicting model, devising 15-day forecasts faster and more accurately.In a new study published inNature, DeepMind reports that in a comparative test between GenCast and the European Center for Medium-Range Weather Forecasts – the premier service that 35 countries around the world rely on to produce their own forecasts – the AI agent was more accurate 97.2 per cent of the time. Accurately predicting the weather could have major benefits: A University of Arizona study from last year found that making forecasts 50 per cent more accurate would save 2,200 lives a year in the U.S., primarily from extreme heat or cold.\n",
      "Companies in Mexico embrace AI to resurrect the dead(Rest of World)\n",
      "Stop using generative AI as a search engine(The Verge)\n",
      "Trans Americans are turning to TikTok to crowdfund their relocations(Wired)\n",
      "Supplied\n",
      "Filterworld by Kyle Chayka, $37.99\n",
      "This week the Globe’s art section rounded upthe most giftable booksfor everyone on your list, including “the extremely online” person. One of the books they suggest isFilterworldby Kyle Chayka, a New Yorker staff writer who reports on internet culture and technology. In this non-fiction book, he explores how algorithmic feeds have homogenized how we create and consume culture, making it less interesting and fulfilling. Sure, it’s not the lightest read to curl up with next to the fire, but it’ll make you think deeply about how we spend our time online.\n",
      "Sabrina Carpenter performs in September.Brendan McDermid/Reuters\n",
      "Every December, online platforms release their year-in-review recaps, listing the top artists, influencers and trends of the previous 12 months. YouTube did something a bit differently this year. Rather than listing the most-watched videos of the year, it identified the top trending topics, based on an analysis including the number of views, uploads and activity by creators. This new methodology reflects the nature of YouTube: People aren’t just watching their favourite creators on the platform. They’re making their own reaction videos, posting commentary and making mash-ups, becoming content creators themselves in the process.\n",
      "This year’s top trending topicswere a mix of video games, niche animated series and big news stories. The only celebrity to make the list was pop star Sabrina Carpenter, who had a breakthrough with her single Espresso, and there was only one reference to Hollywood–blockbusterDeadpool & Wolverine. This shows how YouTube nurtures entertainment outside of the pop culture mainstream, but also how traditional media is becoming less influential in our online spaces.\n",
      "\n",
      "The manufacturing sector is no stranger to innovation. In fact, it’s always been at the forefront of digital transformation, taking the arrival of robotics, the internet and new developments in material science in its stride.\n",
      "However, in 2025, it still finds itself braced for disruption, as manufacturers around the world grapple with the implications of artificial intelligence. There’s also the growing importance of improving sustainability as the climate crisis deepens and building resilience in the face of political and societal uncertainty.\n",
      "In order to meet these challenges, the companies responsible for creating products we use every day are enthusiastically investing in breakthrough technologies as well as adapting to cultural changes, such as the need to rethink skills and training.\n",
      "So let’s take a look at how this will unfold over the next year by overviewing the key trends and opportunities:\n",
      "In 2025, we will see manufacturers rolling out many use cases for generative AI designed to speed up and drive efficiency in manufacturing processes. By leveraging the power of generative design, it will be possible to create stronger, lighter components that make more efficient use of available materials. We’ve already seen aerospace companies leveraging genAI to create newaircraft parts, and automotive manufacturers are using it to optimize vehicle designs. I believe we will see many more innovative use cases in the coming year as manufacturers increasingly integrate genAI into their operations.\n",
      "Robots are not new in manufacturing; in fact, robots have been working in factories for more than 50 years. What is new, however, is the new generation of intelligent robots that are able to work safely and effectively alongside humans, apply themselves to different tasks, and learn to become more efficient at their jobs and navigating their environments. As robots move away from the assembly line andinto the workforce, humans will develop new skills around leading and interacting with automated co-workers – sometimes referred to as “cobots”.\n",
      "Positioning a business asa leaderrather than simply a follower or even a laggard in the AI era will become a growing priority for many manufacturing companies. Put simply, it’s no longer good enough to simply adopt new technologies like robotics, predictive maintenance and automation. As the barriers to entry continue to fall, it has to be done in a way that’s more innovative, effective and efficient than the competition. Developing the capacity not just to follow trends but to identify opportunities to blaze a trail will increasingly become a priority in 2025.\n",
      "There are numerous reasons why sustainability is quickly becoming a business priority for manufacturers in 2025. They include consumer demand, stricter regulations and the simple fact that we’re increasingly seeing the impact of climate disruption in the world around us. Due to this, we can expect to see a strategic switch towards cleaner and greener operations, such as the use of renewable energy, recyclable materials, reductions in emissions, excessive packaging, and water use.\n",
      "There’s a widely-acknowledged skills crisis among industries hoping to reap the opportunities offered by AI, robotics, advanced data analytics and automation. Bridging this skills gap will require manufacturers to rethink the way they hire and train staff, and for many, this will become a critical business priority in 2025. Addressing this challenge may involve investing in upskilling and reskilling, developing apprenticeship programs or forging new relationships with educators and academia.\n",
      "This year, smartphone manufacturer Xiaomiswitched onits fully autonomous dark factory close to Beijing, capable of producing 10 million handsets a year without human intervention. This model will become increasingly common as manufacturers chase improved efficiency, sustainability and reduced waste. While “lights out” factories have been around for a while, Xiaomi’s factory is the first that is able to learn how to operate more efficiently and optimize its own processes thanks to its AI-powered “brain”.\n",
      "There can undoubtedly be cultural barriers to AI adoption. Some people are worried it will replace them or make them redundant, while others believe that decision-making shouldn't be left to machines. While these are all valid concerns, identifying areas where AI can clearly solve problems or create efficiencies while mitigating its potential for causing harm will be a priority for the manufacturing industry in 2025. This will include planning and delivering initiativesfostering an understandingof AI across a workforce and ensuring its benefits are felt by all.\n",
      "The logistical challenges around sourcing components and managing complex inventories and production infrastructure are perfectly suited to automated, intelligent solutions. AI-powered tools leveraging real-time data analytics will enable more accurate demand forecasting and automated decision-making, helping manufacturers to build supply chains that are more resilient and adaptive to changing market conditions. In 2025, AI will enable manufacturers to anticipate disruption more effectively and identify opportunities to improve efficiency, ultimately leading to improved customer experience and business performance.\n",
      "As we move through 2025, the manufacturing sector stands at a pivotal moment of transformation. While challenges around AI adoption, sustainability, and workforce development remain significant, the convergence of smart technologies, automated systems, and sustainable practices is creating unprecedented opportunities for innovation. Companies that successfully navigate these changes – embracing AI-driven efficiency while building resilient, sustainable operations and investing in their workforce – will be best positioned to thrive in manufacturing's next era. The future of manufacturing isn't just about automation and AI – it's about creating smarter, more sustainable, and more adaptive production systems that can meet the challenges of tomorrow.\n",
      "\n",
      "One Community. Many Voices. Create a free account to share your thoughts.\n",
      "Our community is about connecting people through open and thoughtful conversations. We want our readers to share their views and exchange ideas and facts in a safe space.\n",
      "In order to do so, please follow the posting rules in our site'sTerms of Service.We've summarized some of those key rules below. Simply put, keep it civil.\n",
      "Your post will be rejected if we notice that it seems to contain:\n",
      "User accounts will be blocked if we notice or believe that users are engaged in:\n",
      "So, how can you be a power user?\n",
      "Thanks for reading our community guidelines.  Please read the full list of posting rules found in our site'sTerms of Service.\n",
      "\n",
      "In this issue, we delve into the transformative impact of AI on healthcare and pharma, featuring insights on key AI trends from the floor of Frontiers Health, the ongoing battle against drift, and the promise of biological software. Plus, we explore AI's role in drug discovery, commercialisation, and medical information, and take an in-depth look at why drugs fail.\n",
      "Decoding the future: Key AI trends and innovations at Frontiers Health:From patient autonomy to repurposed drugs, Frontiers Health 2024 showcased the transformative potential of AI in healthcare. Here, we explore five key trends and innovations that caught our attention at this year’s event.\n",
      "Pharma and the ongoing battle against AI drift:Addressing the challenge of AI drift is critical for maintaining the reliability and effectiveness of AI systems in pharma. To find out more, Pharmaphorum web editor, Nicole Raleigh, examines how companies are navigating algorithmic shifts that threaten operational accuracy.\n",
      "Big interview: Inceptive's Jakob Uszkoreit on the promise of biological software:In an exclusive interview, deep learning pioneer, Jakob Uszkoreit, shares his journey from groundbreaking success at Google to the uncharted territory of biological software, and discusses how AI is bridging biology and computation for faster, more effective breakthroughs\n",
      "From R&D to ROI: AI’s impact on pharma commercialisationAI is transforming R&D ROI by accelerating drug discovery timelines and optimising resource allocation. Here, EVERSANA’s, Scott Snyder, explores how AI-powered analytics are enhancing market access and commercialisation strategies.\n",
      "Right to reply: ChatGPT and AI in healthcareMuch has been said about the potential (both good and bad) of AI in healthcare. But, to get both sides of the story, and uncover the true intentions of GenAI, Deep Dive sat down with the notorious player that sparked the current hype cycle: Chat-GPT.\n",
      "Why drugs fail: The unrelenting challenge of finding new drugsDespite advances in technology, drug failure remains a significant hurdle for the industry. Jordan Lane, co-founder and CSO for Ignota Labs, breaks down the scientific and structural barriers that contribute to high drug failure rates and explores how AI may help to address them.\n",
      "A strategic framework for evaluating AI in drug discovery:Evaluating AI’s effectiveness in drug discovery requires a robust and strategic framework. Here, L.E.K. Consulting provides a roadmap for assessing AI tools, ensuring they align with scientific and commercial goals.\n",
      "Navigating the evolving landscape of medical information with AI-powered solutionsIQVIA’s Simon Johns breaks down how AI-powered solutions are reshaping the way medical information is processed and delivered, improving accessibility and accuracy. Learn about the technologies driving this shift and their implications for the future of medical communication.\n",
      "Read Deep Dive:AI 2024in full pharmaphorum’s digital magazineDeep Diveprovides objective, issue-driven views, analysis, high-level interviews and unique research for pharmaceutical companies, biotech firms and the wider healthcare sector. Subscribe tofuture issues of Deep Dive.\n",
      "\n",
      "Worawut - stock.adobe.com\n",
      "As we move into 2025, the landscape of human resources (HR) is heading for a significant transformation.Artificial intelligence(AI) is set to revolutionise workforce collaboration, efficiency, and talent management.\n",
      "For HR leaders, harnessing the power of AI will be essential toattract, engage, and retain top talentin an increasingly competitive market.\n",
      "AI is reshaping and revamping HRby automating routine and mundane tasks such as interview scheduling, data entry, and CV screenings. This automation allows HR teams to focus on strategic initiatives that add real value to employees, such as developing diverse cultures, offering tailored development programmes, and increasing engagement.\n",
      "AI-powered analytics can identify workforce trends, predict employee turnover, and suggest to retain top talent. These insights enable HR leaders to make data-driven decisions to support a high-performance culture, ultimately improving employee engagement and organisational performance.\n",
      "Just look at Unilever, which uses AI to streamline its recruitment process. By using AI-driven assessments and video interview analytics, Unilever has significantly reduced time-to-hire while enhancing the candidate experience. Additionally, AI can streamline performance management by providing continuous feedback and personalised development plans. This shift towards real-time performance management fosters a culture of continuous improvement, where the team receives timely feedback and support to achieve their goals, leading to higher engagement levels and better retention rates.\n",
      "As the demand on sourcing talent with scarce skills continues in 2025, attracting top talent needs innovative strategies. AI can play a pivotal role in enhancing the candidate experience. Imagine AI-driven chatbots engaging with candidates in real-time, answering their questions and providing personalised information about the company and the role. This immediate engagement can significantly improve the candidate experience, making the organisation more attractive.\n",
      "AI can also help create a more inclusive hiring processes by eliminating unconscious biases from recruitment. AI algorithms can analyse job descriptions to ensure they are free from biased language and assess candidates based on objective criteria. This is an incredibly important step to support organisations in attracting and growing a more diverse and inclusive workforce, which is crucial for driving innovation and business success.\n",
      "Retaining your team is equally important as attracting it. AI can help HR leaders identify early signs of people’s disengagement or dissatisfaction. For instance, AI-powered sentiment analysis can monitor employee communications and flag any negative sentiments, allowing HR and managers to intervene proactively. By addressing issues before they escalate, organisations can improve the satisfaction, happiness and ultimately retention of the team.\n",
      "AI can also facilitate personalised employee development. By analysing skills, performance data, and career aspirations, AI can recommend tailored development programmes and career paths for each individual. This personalised approach to development can help people feel valued and supported.\n",
      "24% of all workersare worried that AI will soon make their job obsolete. HR leaders have a crucial role in addressing these concerns and ensuring their teams are ready for AI integration. Providing training and the right tools to integrate AI smoothly is essential. By fostering a culture of continuous improvement and responsible AI use, HR can drive greater efficiency and empower the entire workforce.\n",
      "AI is more likely to enhance roles rather than replace them, and HR leaders should embrace AI ethically and transparently. This involves being clear about how AI is used, ensuring data privacy, and maintaining a human touch in all interactions. By doing so, HR can build trust and create a positive environment where AI is seen as a tool for empowerment rather than a threat.\n",
      "As we approach 2025 and beyond, the integration of AI in HR will continue to evolve. Future trends may include more sophisticated AI-driven talent management systems, enhanced predictive analytics for workforce planning, and even more personalised employee experiences powered by AI. HR leaders who stay ahead of these trends and continually innovate will be well-positioned to lead their organisations into the future.\n",
      "Looking to the New Year, AI will play a pivotal role in enhancing HR functions, making them more efficient, strategic, and employee centric. By leveraging AI to attract, engage, and retain top talent, organisations can stay competitive in a rapidly evolving job market. HR leaders who embrace AI responsibly and proactively will be well-positioned to drive their organisations forward, creating workplaces that are both productive and fulfilling for their team.\n",
      "Toria Walters is chief people officer atANS, a digital transformation provider and Microsoft’s UK Services Partner of the Year 2024. Headquartered in Manchester, it offers public and private cloud, security, business applications, low code, and data services to thousands of customers, from enterprise to SMB and public sector organisations.\n",
      "\n",
      "This year’s Amazon Web Services conference, re:Invent 2024, confirmed a few trends we’ve been tracking in the artificial intelligence boom. These include massive changes in the cloud infrastructure landscape with investment of hundreds of billions of dollars in an AI infrastructure arms race, as well as the struggle of enterprises to find return on investment in AI.\n",
      "This week, both of these trends had interesting twists. The week started off with the resignation of Intel CEO Pat Gelsinger, demonstrating what happens when you miss a huge market shift. Intel, even before Gelsinger took over, was poorly positioned in graphics processing units, the area that NVIDIA pioneered. But Gelsinger perhaps made things worse by focusing on an approach favoring the buildout of domestic and European manufacturing facilities and a foundry business, all based in part on government funding.\n",
      "AWShad plenty of announcements in hardwareto demonstrate that it will stay in front of the AI arms race, including ensuring its supply of chips. In addition to buying chips from AI compute leaders NVIDIA and AMD, AWS has its own line of chips, including Graviton and Trainium. Here at re:Invent, it unveiled mass-scale AI clusters, complete with its own networking and interconnect technology, as well as general availability of its Trainium2 AI training chip.\n",
      "LAS VEGAS, NEVADA - DECEMBER 3: Amazon Web Services (AWS) CEO Matt Garman delivers a keynote address... [+]during AWS re:Invent 2024, a conference hosted by Amazon Web Services, at The Venetian Las Vegas on December 3, 2024 in Las Vegas, Nevada. (Photo by Noah Berger/Getty Images for Amazon Web Services)\n",
      "On the enterprise ROI front, I saw several examples of this in the re:Invent keynotes as well as the analyst conference, where companies as diverse as Apple, JP Morgan, The Hartford, Novo Nordisk, and others demonstrated how they are using AI to gain ROI in specific use cases.\n",
      "Let’s dive into these two areas in more detail.\n",
      "Walking around the re:Invent conference, which hosted 60,000 people, you can talk to anybody from cloud engineers to Fortune 500 CEOs. The conference is of course owned and operated by AWS, so it’s an annual tradition for AWS to launch a barrage of technology announcements—literally hundreds—that demonstrate why it’s still the leading cloud operator.\n",
      "The question is, will AI help or hurt AWS in the long run? In addition to AWS competitors Microsoft Azure and Google Cloud, the AI boom has spawned a raft of AI-focused cloud providers, including Lambda and CoreWeave, the latter of which has achieved a valuation of tens of billions of dollars in just a few years.\n",
      "AWS is of course determined not to let AI derail its leadership. Its announcements range from huge hardware projects to feature upgrades of its AI services SageMaker and Bedrock.\n",
      "On the hardware front, AWS showed it has a diversification strategy to provide its own hardware, even though it buys from many suppliers, including NVIDIA. AWS announced general availability of Amazon Elastic Compute Cloud (Amazon EC2) on Trn2 instances, which feature clusters of 16 Trn2 chips. And Trn2 can be scaled up using hardware clustering solutions. A separate Trn2 UltraServer, now in preview, features a cluster of 64 Trn2 chips across four Trn2 instances.\n",
      "AWS CEO Matt Garman positioned it as a broadening of the market rather than as a competitive alternative to NVIDIA.\n",
      "\"NVIDIA is an incredibly important partner of ours. AMD is an incredible partner as well. Today it is true that the vast majority of workloads run on NVIDIA. We're so early where GenAI can be, that I think Trainium increases the size of the pie. It's not going to be at the expense [of others].\"\n",
      "\n",
      "The company is also planning a massive supercomputer named Project Rainier in partnership with Anthropic (which AWS has invested in), based on UltraServers. It's set to debut in 2025. Anthropic isn’t alone. Other Trn2customers includeDatabricks, Datadog, Ricoh, Hugging Face, and PyTorch.\n",
      "It wouldn’t be re:Invent without lots of geeky upgrades to AWS services. AWS has rebranded its SageMaker ML service as SageMaker AI, which sports a bunch of enhancements designed to grease the wheels of ML-based analytics. These include the SageMaker HyperPod, whichcoordinates modeling workloads.\n",
      "In a keynote talk at the conference this week, Swami Sivasubramanian, VP of AI and data at AWS, outlined a raft of new services that streamline model training and inferencing for enterprise customers.\n",
      "“We’re seeing the convergence of big data, analytics, machine learning, and generative AI,” said Sivasubramanian. And AWS has built on a range of past successes to meet demand, he said.\n",
      "In another example, the company’s other AI service, Bedrock, offers a range of large language models. This year featuresmulti-agent collaboration, which allows agents to coordinate across different tasks. Example: For a financial services firm, according to AWS’s online announcement, “specialized agents could coordinate to gather data, analyze trends, and provide actionable recommendations—working in parallel to improve response times and precision.” This feature is currently available in the US East (N. Virginia), US West (Oregon), and Europe (Ireland) AWS Regions.\n",
      "Queue up the next topic: enterprise AI. The world is filled with chatter about whether AI can fulfill its promise in delivering ROI to the enterprise.\n",
      "There are of course many skeptics, including Render founder and CEO Anurag Goel, who was also a former executive at Stripe. Render has a cloud automation platform that Goel says is being adopted by “hundreds of thousands of developers per month.” He told me that he hadn’t seen a huge demonstration of ROI at the conference.\n",
      "“AWS announced a lot of services around AI but they lack a coherent end-to-end theme,” Goel told me in the hallway of the Venetian. “The business value and the ROI remains unclear.”\n",
      "Despite some skepticism about the AI endgame, some attendees said there has been a shift in thinking from “god” products to more tactical technology using AI. Adam Jacob, cofounder and CEO of System Initiative, told me the new thinking embodies a more tactical, focused approach he refers to as “micro AI.”\n",
      "“As an industry, we started out by thinking, ‘We're going to have a single god robot that we just pump all the exabytes of data to and we just let the god machine sort it out.’ We're learning that that creates a terrible user experience and is incredibly hard to track and secure. Instead, we're starting to build micro AI experiences that form a series of small experiences that build up to really compelling big ones.\"\n",
      "The case for micro AI makes sense. Generalized AI is difficult and has key challenges such as accuracy, data security, and data provenance. But if you can focus on specific solutions with an AI tool, you might have a better shot at ROI gratification.\n",
      "In its analyst conference, AWS did a good job of presenting ROI examples from customers, which was a noticeable change from last year, when the market was still riding the pink cloud of AI hype.\n",
      "In its briefing sessions for industry analysts, AWS had examples of compelling ROI-driven case studies. Companies presenting included Apple, JP Morgan, The Hartford, Merck, New York Life, and Novo Nordisk, among others.\n",
      "Louise Lind Skov, head of content digitalisation with Danish pharmaceutical giant Novo Nordisk. showed how the company reduced the time to create regulatory documentation from two months to several minutes by building its own AI-driven tool on AWS, which it calls NovoScribe.\n",
      "“From a medical writing perspective, this would have required thousands of hours of work,” said Skov.\n",
      "NovoScribe seems to be a great example of micro AI. By focusing on a specific use case and process, Novo Nordisk was able to deliver specific efficiencies.\n",
      "This will be a big theme going forward as the AI wave takes a circuitous path to technology nirvana. Nobody has a god AI app yet, but there are certainly many tools available to solve everyday problems and deliver tangible results in focused areas.\n",
      "\n",
      "One Community. Many Voices. Create a free account to share your thoughts.\n",
      "Our community is about connecting people through open and thoughtful conversations. We want our readers to share their views and exchange ideas and facts in a safe space.\n",
      "In order to do so, please follow the posting rules in our site'sTerms of Service.We've summarized some of those key rules below. Simply put, keep it civil.\n",
      "Your post will be rejected if we notice that it seems to contain:\n",
      "User accounts will be blocked if we notice or believe that users are engaged in:\n",
      "So, how can you be a power user?\n",
      "Thanks for reading our community guidelines.  Please read the full list of posting rules found in our site'sTerms of Service.\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n'.join(pd.DataFrame(results).text.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
